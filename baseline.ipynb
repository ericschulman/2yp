{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.interpolate import interp1d #pre written interpolation function\n",
    "from scipy.interpolate import griddata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enum_other_states(n, min_s, max_s):\n",
    "    \"\"\"enumerate the state. for all palyers except player i\n",
    "    (1,1,2) is equivalent to (1,2,1) from firm 1's pespective\"\"\"\n",
    "    \n",
    "    states_i = range(min_s,max_s)\n",
    "    if n <=1:\n",
    "        states = [[i] for i in states_i]\n",
    "        return states\n",
    "    else:\n",
    "        states = []\n",
    "        states_j = enum_other_states(n-1,min_s,max_s)\n",
    "        for i in states_i:\n",
    "            for j in states_j:\n",
    "                if j[0] >= i:\n",
    "                    state_ij = [i] + j \n",
    "                    states.append(state_ij)\n",
    "        return states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class States:\n",
    "    \"\"\"class for dealing with the states\n",
    "    these things are apparently really complex\n",
    "    there are just a ton of them\"\"\"\n",
    "    \n",
    "    my_states = None #type nparray\n",
    "    other_states = None #type np array 2d\n",
    "    n = 0 #number of players\n",
    "    max_states = 0\n",
    "    min_states = 0\n",
    "    \n",
    "\n",
    "    def __init__(self, n, min_s,max_s):\n",
    "        \"\"\"initialize important class attributes\"\"\"\n",
    "        self.n, self.min_states, self.max_states = n, min_s, max_s\n",
    "      \n",
    "    \n",
    "    def gen_states(self):\n",
    "        \"\"\"compute all relevant states for firm i\n",
    "        the trick is ommiting equivalent states\n",
    "        this is taken care of in the helper function\"\"\"\n",
    "        \n",
    "        #avoid typing self a million times\n",
    "        n, min_s, max_s  = self.n, self.min_states, self.max_states\n",
    "        \n",
    "        #setup other states\n",
    "        other_states =  np.array(enum_other_states(n-1,min_s,max_s))\n",
    "        num_others = other_states.shape[0]\n",
    "        \n",
    "        #initialize my states based on this\n",
    "        my_states = np.arange(min_s,max_s)\n",
    "        my_states = np.repeat(my_states,num_others )\n",
    "        self.my_states = my_states\n",
    "        \n",
    "        #copy other states enough times\n",
    "        other_states = other_states.reshape((1,num_others,n-1))\n",
    "        other_states = np.tile(other_states,(max_s - min_s,1,1))  \n",
    "        other_states = other_states.reshape(num_others*(max_s - min_s),n-1)\n",
    "        self.other_states = other_states\n",
    "    \n",
    "    \n",
    "    \n",
    "    def make_states(self, my_states, other_states):\n",
    "        \"\"\"special initializer for states\n",
    "        ensures they are not too big or too small\"\"\"\n",
    "        \n",
    "        assert np.array(other_states).shape[1] == (self.n -1)\n",
    "        \n",
    "        n, min_s, max_s  = self.n, self.min_states, self.max_states\n",
    "        #make a copy to avoid side effects\n",
    "        new_states = States(n,min_s,max_s)\n",
    "        \n",
    "        #ensure other my states are good\n",
    "        my_states = np.array(my_states)\n",
    "        my_states = np.minimum(max_s - 1, np.array(my_states))\n",
    "        new_states.my_states = np.maximum(min_s, np.array(my_states))\n",
    "        \n",
    "        #ensure other states are good\n",
    "        other_states = np.sort(other_states,axis=1)\n",
    "        other_states = np.minimum(max_s - 1, np.array(other_states))\n",
    "        new_states.other_states = np.maximum(min_s, np.array(other_states))\n",
    "        \n",
    "        return new_states\n",
    "    \n",
    "    \n",
    "    def get_len(self):\n",
    "        return len(self.other_states)\n",
    "    \n",
    "    \n",
    "    def get_all(self):\n",
    "        \"\"\"return all the states\"\"\"\n",
    "        reshaped_states = self.my_states.reshape((len(self.my_states),1))\n",
    "        return np.concatenate( (reshaped_states, self.other_states), axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_function(states, values):\n",
    "    \"\"\"returns a function\n",
    "    the function uses the grid data to figure out return value\"\"\"\n",
    "    f = lambda eval_states: griddata(states.get_all(), values, \n",
    "                                     eval_states.get_all(), method='linear')\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_bids(policy, states):\n",
    "    \"\"\"return the other players bids\n",
    "    given the state by 'switching perspective'\n",
    "    to other firm\"\"\"\n",
    "    \n",
    "    other_bids = []\n",
    "    for i in range(1,states.n):\n",
    "        other_states = states.get_all()\n",
    "        my_other = other_states[:,i]\n",
    "        other = np.delete(other_states, i, axis=1)\n",
    "        other_states = states.make_states(my_other, other)\n",
    "        other_bids.append( policy(other_states) )\n",
    "    return np.array(other_bids).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.1 1.1 2.2]\n",
      "[-0.1  0.9  0.8]\n",
      "[[1.  1.  1.5]\n",
      " [1.  1.  2. ]\n",
      " [2.  1.  2. ]]\n"
     ]
    }
   ],
   "source": [
    "def cost(states, shock,theta):\n",
    "    \"\"\"return the cost for firm 0\"\"\"\n",
    "    return theta*states.my_states + shock\n",
    "\n",
    "\n",
    "def profit(bids, states, contract, shock, theta):\n",
    "    \"\"\"return firm 0's profit\"\"\"\n",
    "    my_bids = bids[:,0]\n",
    "    other_bids = np.delete(bids,0,axis=1)\n",
    "    profits = contract*( my_bids < np.min(other_bids, axis=1) )*(my_bids - cost(states,shock,theta))  \n",
    "    return profits\n",
    "\n",
    "\n",
    "def update_state(bids, states, contract):\n",
    "    \"\"\"update all firms states based on bids\"\"\"\n",
    "    new_states = contract*(  bids< np.min(bids) ) + states.get_all()\n",
    "    return states.make_states(new_states[:,0],np.delete(new_states,0,axis=1))\n",
    "\n",
    "\n",
    "##### unit testing\n",
    "\n",
    "#make some bids\n",
    "bids = np.array([1,2,3])\n",
    "\n",
    "#make some states\n",
    "states = States(3,1,3)\n",
    "states.gen_states()\n",
    "new_states = states.make_states([1,1,2],[[1.5,1],[1,5],[1,4.3]])\n",
    "\n",
    "#make a policy\n",
    "values = np.concatenate([6*np.ones(states.get_len()/2),8*np.ones(states.get_len()/2)])\n",
    "policy = create_function(states, values)\n",
    "\n",
    "#learn mkt outcome for others\n",
    "other_bids = calc_bids(policy, new_states)\n",
    "all_bids = bids.reshape(len(bids),1)\n",
    "all_bids = np.concatenate((all_bids,other_bids), axis=1)\n",
    "\n",
    "#tests\n",
    "print cost(new_states,0,1.1)\n",
    "print profit(all_bids,new_states,1,0,1.1)\n",
    "print update_state(all_bids,new_states,1.1).get_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def operator(v_init, p_init, bids, states, theta, beta):\n",
    "    \"\"\"update the value and the policy function for player 0\n",
    "    \n",
    "    since we are looking for symmetric eq, there is really just 1\n",
    "    policy and value to keep track of\"\"\"\n",
    "    \n",
    "    #initialize contract and state to 0\n",
    "    contract = 1\n",
    "    shock = 0\n",
    "    \n",
    "    #repeat bids/states per each bid\n",
    "    my_bids = np.repeat(bids,states.get_len())\n",
    "    bid_states = states.get_all()\n",
    "    bid_states = np.tile(bid_states,(len(bids),1))\n",
    "    bid_states = states.make_states(bid_states[:,0],np.delete(bid_states,0,axis=1))\n",
    "    \n",
    "    #other bids in each bid state and concat with my bids\n",
    "    other_bids = calc_bids(p_init, bid_states)\n",
    "    all_bids = my_bids.reshape(len(my_bids),1)\n",
    "    all_bids = np.concatenate((all_bids,other_bids), axis=1)\n",
    "    \n",
    "    #calculate see how the states would update\n",
    "    next_states = update_state(all_bids, bid_states, contract)\n",
    "    \n",
    "    #calculate the value of the next state\n",
    "    v_new = profit(all_bids, bid_states, contract,  shock, theta)\n",
    "    v_new = v_new + beta*v_init(next_states)\n",
    "    \n",
    "    #reshape v_new to find argmax\n",
    "    v_new = v_new.reshape((len(bids),states.get_len()))\n",
    "    \n",
    "    policy = np.argmax(v_new,axis=1)\n",
    "    policy = bids[policy]\n",
    "    policy = create_function(states, policy)\n",
    "    \n",
    "    value = create_function(states, v_new)\n",
    "    \n",
    "    return policy, value\n",
    "\n",
    "#make some states/bids\n",
    "bids = np.arange(1,6)\n",
    "states = States(3,1,3)\n",
    "states.gen_states()\n",
    "\n",
    "#make a policy\n",
    "values = np.concatenate([6*np.ones(states.get_len()/2),8*np.ones(states.get_len()/2)])\n",
    "policy = create_function(states, values)\n",
    "\n",
    "policy, value = operator(policy, policy, bids, states, 1.1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_functions():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  markov_perfect_eq(initial_value, error, maxiter):\n",
    "    \"\"\"calculate the value function in a symmetric\n",
    "        markov perfect equilibria\"\"\"\n",
    "    \n",
    "    #initialize loop variables\n",
    "    v0 = np.ones(len(states))\n",
    "    v_next = operator(a, theta1, cost, v0, v1)\n",
    "    \n",
    "    while  maxiter >= 0 and ( \n",
    "            np.abs(v0 - v0_next ).max() > error\n",
    "           or np.abs(v1 - v1_next ).max()  > error ):\n",
    "        \n",
    "        #iterate loop variables for each player\n",
    "        for i in range(N):\n",
    "            v0, v1 = v0_next, v1_next\n",
    "            v0_next, v1_next = operator(a, theta1, cost, v0, v1)\n",
    "            maxiter = maxiter -1\n",
    "\n",
    "    return  value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
