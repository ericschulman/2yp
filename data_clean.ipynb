{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata = pd.read_csv('data/milk.csv')\n",
    "data = rawdata.copy()\n",
    "\n",
    "data = rawdata.copy()\n",
    "\n",
    "#lag auctions within 1 vendor\n",
    "data = data.sort_values(['VENDOR','YEAR','MONTH','DAY','SYSTEM'])\n",
    "bids = data.groupby(['VENDOR','YEAR','MONTH','DAY','SYSTEM'], as_index=False).mean()\n",
    "bids = bids[['VENDOR','YEAR','MONTH','DAY','SYSTEM']]\n",
    "sys_lag = bids.groupby(['VENDOR']).shift(1)\n",
    "bids['VENDOR_LAG'] = sys_lag['SYSTEM']\n",
    "data = pd.merge(data, bids, how='left', \n",
    "                 on=['VENDOR','YEAR','MONTH','DAY','SYSTEM'], suffixes=('', '_LAG') ) \n",
    "\n",
    "#lag auctions\n",
    "data =data.sort_values(['YEAR','MONTH','DAY','SYSTEM'])\n",
    "aucts =  data.groupby(['YEAR','MONTH','DAY','SYSTEM'], as_index=False).mean()\n",
    "aucts = aucts[['YEAR','MONTH','DAY','SYSTEM']]\n",
    "auct_lag = aucts.shift(1)\n",
    "aucts['AUCT_LAG'] = auct_lag['SYSTEM']\n",
    "data = pd.merge(data, aucts, how='left', \n",
    "                 on=['YEAR','MONTH','DAY','SYSTEM'], suffixes=('', '_LAG') ) \n",
    "\n",
    "prev_auct = 1.*(data['AUCT_LAG'] == data['VENDOR_LAG'])\n",
    "data['PAST_AUCT'] = prev_auct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#general house keeping\n",
    "data = data[ (data['YEAR']>=1980)]\n",
    "data = data[(data['MONTH'] >= 4) & (data['MONTH'] <= 9) & (data['DAY'] !=0) ] #need data with time index\n",
    "data = data[(~np.isnan(data['SCORE']) ) & (data['QSCORE']!=0 )] #need data with QWW and WW\n",
    "\n",
    "\n",
    "data['COOLER'] = data['COOLER'].fillna(0)\n",
    "data['ESC'] = data['ESC'].fillna(0)\n",
    "data['ONEBID'] = 1.*(data['NUM'] == 1)\n",
    "\n",
    "#various keys\n",
    "milk = ['SCORE']\n",
    "auct_key = ['YEAR','MONTH','DAY','SYSTEM','FMOZONE']\n",
    "cts = ['FMO','GAS','POPUL','QSCORE']\n",
    "dummies = ['COOLER','ESC', 'NUM'] #delete num?\n",
    "\n",
    "\n",
    "#baseline stuff/logs\n",
    "lmilk = ['L'+x for x in milk]\n",
    "lcts = ['L'+x for x in cts]\n",
    "data[lcts] = np.log(data[cts])\n",
    "data[lmilk] = np.log(data[milk])\n",
    "\n",
    "#set up lags\n",
    "lags = 10\n",
    "lagkeys = [l+str(i) for l in ['LSCORE_min','LSCORE_max'] for i in range(1,1+lags)]\n",
    "aucts = data.groupby(auct_key, as_index=False)[milk].mean()[auct_key]\n",
    "\n",
    "#note data is already sorted by date\n",
    "data = data.sort_values(['YEAR','MONTH','DAY'])\n",
    "min_lag = data.groupby(auct_key, as_index=False).min()\n",
    "for t in range(1,1+lags):\n",
    "    min_lagt = min_lag.shift(t)[lmilk]\n",
    "    min_lagt = pd.concat((aucts, min_lagt), axis=1)\n",
    "    data = pd.merge(data, min_lagt, how='left', on=auct_key, suffixes=('', '_min%s'%(t)) ) \n",
    "    \n",
    "max_lag = data.groupby(auct_key, as_index=False).max()\n",
    "for t in range(1,1+lags):\n",
    "    max_lagt = max_lag.shift(t)[lmilk]\n",
    "    max_lagt = pd.concat((aucts, max_lagt), axis=1)\n",
    "    data = pd.merge(data, max_lagt, how='left', on=auct_key, suffixes=('', '_max%s'%(t)) )    \n",
    "\n",
    "    \n",
    "#set up lags but prev year \n",
    "yearlags = 3\n",
    "year_lagkeys = [l+str(i) for l in ['LSCORE_miny','LSCORE_maxy'] for i in range(1,1+yearlags)]\n",
    "\n",
    "\n",
    "#note data is sorted by year now\n",
    "data = data.sort_values(['SYSTEM','YEAR','MONTH','DAY'])\n",
    "\n",
    "year_min_lag = data.groupby(auct_key, as_index=False).min().sort_values(['SYSTEM','YEAR','MONTH','DAY'])\n",
    "for t in range(1,1+lags):\n",
    "    min_lagt = year_min_lag.groupby(['SYSTEM']).shift(t)[lmilk]\n",
    "    min_lagt = pd.concat((aucts, min_lagt), axis=1)\n",
    "    data = pd.merge(data, min_lagt, how='left', on=auct_key, suffixes=('', '_miny%s'%(t)) )\n",
    "\n",
    "year_max_lag = data.groupby(auct_key, as_index=False).max().sort_values(['SYSTEM','YEAR','MONTH','DAY'])\n",
    "for t in range(1,1+lags):\n",
    "    max_lagt = year_max_lag.groupby(['SYSTEM']).shift(t)[lmilk]\n",
    "    max_lagt = pd.concat((aucts, max_lagt), axis=1)\n",
    "    data = pd.merge(data, max_lagt, how='left', on=auct_key, suffixes=('', '_maxy%s'%(t)) ) \n",
    "    \n",
    "\n",
    "#pre processing to help fmozones\n",
    "fe = ['FMOZONE']\n",
    "data.loc[(data['FMOZONE'] =='1A') , 'FMOZONE'] = '1'\n",
    "\n",
    "fekeys = []\n",
    "for effect in fe:\n",
    "    fes = pd.get_dummies(data[effect], drop_first=True)\n",
    "    fekeys = fekeys+ list(fes.columns)\n",
    "    data = pd.concat((data, fes), axis=1)\n",
    "\n",
    "    \n",
    "bid_key = auct_key + ['VENDOR'] + ['COUNTY']\n",
    "covariates = lcts + dummies + fekeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write this to csvs with all the lags\n",
    "reg0 = data.copy()[bid_key + lmilk + covariates + year_lagkeys + lagkeys + ['INC','PAST_AUCT', 'WIN']]\n",
    "reg0.to_csv('data/clean_milk0.csv')\n",
    "\n",
    "#only drop data 5 periods back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg1 = reg0.copy()[bid_key + lmilk + covariates + ['INC']]\n",
    "reg1 = reg1.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 LSCORE   R-squared:                       0.163\n",
      "Model:                            OLS   Adj. R-squared:                  0.161\n",
      "Method:                 Least Squares   F-statistic:                     71.77\n",
      "Date:                Thu, 25 Jul 2019   Prob (F-statistic):          1.08e-147\n",
      "Time:                        16:23:50   Log-Likelihood:                 4127.0\n",
      "No. Observations:                4056   AIC:                            -8230.\n",
      "Df Residuals:                    4044   BIC:                            -8154.\n",
      "Df Model:                          11                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -2.2626      0.077    -29.423      0.000      -2.413      -2.112\n",
      "LFMO           0.2045      0.028      7.238      0.000       0.149       0.260\n",
      "LGAS           0.0237      0.004      5.570      0.000       0.015       0.032\n",
      "LPOPUL         0.0153      0.003      4.713      0.000       0.009       0.022\n",
      "LQSCORE       -0.0201      0.003     -5.870      0.000      -0.027      -0.013\n",
      "COOLER         0.0180      0.003      5.787      0.000       0.012       0.024\n",
      "ESC           -0.0270      0.003     -9.308      0.000      -0.033      -0.021\n",
      "NUM            0.0055      0.001      3.848      0.000       0.003       0.008\n",
      "3             -0.0706      0.004    -16.172      0.000      -0.079      -0.062\n",
      "6             -0.0427      0.013     -3.319      0.001      -0.068      -0.017\n",
      "7             -0.0897      0.015     -6.027      0.000      -0.119      -0.061\n",
      "9             -0.0512      0.004    -12.325      0.000      -0.059      -0.043\n",
      "==============================================================================\n",
      "Omnibus:                      284.052   Durbin-Watson:                   1.204\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1357.200\n",
      "Skew:                           0.122   Prob(JB):                    1.94e-295\n",
      "Kurtosis:                       5.823   Cond. No.                         970.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "#baseline\n",
    "\n",
    "fit1 = sm.OLS(reg1['LSCORE'], sm.add_constant(reg1[covariates] ) ).fit()\n",
    "print(fit1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 LSCORE   R-squared:                       0.180\n",
      "Model:                            OLS   Adj. R-squared:                  0.178\n",
      "Method:                 Least Squares   F-statistic:                     74.05\n",
      "Date:                Thu, 25 Jul 2019   Prob (F-statistic):          2.01e-164\n",
      "Time:                        16:23:59   Log-Likelihood:                 4168.3\n",
      "No. Observations:                4056   AIC:                            -8311.\n",
      "Df Residuals:                    4043   BIC:                            -8229.\n",
      "Df Model:                          12                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -2.2448      0.076    -29.477      0.000      -2.394      -2.096\n",
      "LFMO           0.1998      0.028      7.141      0.000       0.145       0.255\n",
      "LGAS           0.0251      0.004      5.958      0.000       0.017       0.033\n",
      "LPOPUL         0.0145      0.003      4.497      0.000       0.008       0.021\n",
      "LQSCORE       -0.0188      0.003     -5.567      0.000      -0.025      -0.012\n",
      "COOLER         0.0177      0.003      5.747      0.000       0.012       0.024\n",
      "ESC           -0.0281      0.003     -9.769      0.000      -0.034      -0.022\n",
      "NUM            0.0029      0.001      1.973      0.049    1.81e-05       0.006\n",
      "3             -0.0718      0.004    -16.604      0.000      -0.080      -0.063\n",
      "6             -0.0407      0.013     -3.191      0.001      -0.066      -0.016\n",
      "7             -0.0904      0.015     -6.132      0.000      -0.119      -0.061\n",
      "9             -0.0533      0.004    -12.936      0.000      -0.061      -0.045\n",
      "INC           -0.0295      0.003     -9.121      0.000      -0.036      -0.023\n",
      "==============================================================================\n",
      "Omnibus:                      300.428   Durbin-Watson:                   1.109\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1564.605\n",
      "Skew:                           0.097   Prob(JB):                         0.00\n",
      "Kurtosis:                       6.036   Cond. No.                         970.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "#incumbency\n",
    "fit2 = sm.OLS(reg1['LSCORE'], sm.add_constant(reg1[covariates+ ['INC']] ) ).fit()\n",
    "print(fit2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    fit1       se1         fit2       se2\n",
      "Obs.         4056.000000       NaN  4056.000000       NaN\n",
      "$R^2$           0.163326       NaN     0.180194       NaN\n",
      "(Intercept)    -2.262603  0.076363    -2.244822  0.076179\n",
      "Raw milk        0.204512  0.028012     0.199804  0.028032\n",
      "Gas             0.023697  0.004212     0.025111  0.004159\n",
      "Population      0.015321  0.003762     0.014480  0.003766\n",
      "Quantity       -0.020052  0.003983    -0.018843  0.003989\n",
      "Cooler          0.017962  0.003073     0.017659  0.003053\n",
      "Escalated      -0.026995  0.002837    -0.028074  0.002817\n",
      "No. Bidders     0.005542  0.001417     0.002872  0.001458\n",
      "Waco           -0.070571  0.004733    -0.071764  0.004772\n",
      "St. Angelo     -0.042726  0.010331    -0.040681  0.010791\n",
      "Austin         -0.089732  0.023023    -0.090389  0.022093\n",
      "San Antonio    -0.051186  0.005135    -0.053267  0.005111\n",
      "Incumbency           NaN       NaN    -0.029550  0.003050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erichschulman/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "#2 create a table.\n",
    "\n",
    "df = pd.concat([fit1.params, fit1.HC0_se, fit2.params, fit2.HC0_se], axis=1)\n",
    "\n",
    "\n",
    "df.loc['$R^2$'] =  [fit1.rsquared,np.NaN,fit2.rsquared,np.NaN]\n",
    "df.loc['Obs.'] =  [int(reg1.shape[0]),np.NaN, int(reg1.shape[0]),np.NaN]\n",
    "\n",
    "\n",
    "nice_cov = {'const':'(Intercept)', \n",
    "            'LFMO':'Raw milk',\n",
    "            'LGAS':'Gas',\n",
    "            'LPOPUL':'Population', \n",
    "            'LQSCORE':'Quantity',\n",
    "            'COOLER':'Cooler',\n",
    "            'ESC':'Escalated',\n",
    "            'NUM':'No. Bidders', #+ fekeys\n",
    "            '3':'Waco','6':'St. Angelo', '7':'Austin', '9':'San Antonio',\n",
    "            'INC':'Incumbency' }\n",
    "\n",
    "\n",
    "#fix column names\n",
    "df = df.reindex(index = ['Obs.','$R^2$', 'const'] + covariates + ['INC'])\n",
    "df = df.rename(columns = {0:'fit1',1:'se1',2:'fit2',3:'se2'})\n",
    "df = df.rename(index = nice_cov)\n",
    "print(df)\n",
    "\n",
    "df.to_csv('baseline.csv',  float_format='%.4f', na_rep = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
