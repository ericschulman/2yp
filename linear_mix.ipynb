{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.base.model import GenericLikelihoodModel\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate some fake data\n",
    "\n",
    "n = 1000\n",
    "beta01, beta11 = 5,-3\n",
    "beta02, beta12 = 2, 3\n",
    "\n",
    "\n",
    "#set up regression mixture\n",
    "x1 = np.random.uniform(0, 5, size=300)\n",
    "x2 = np.random.uniform(0, 5, size=600)\n",
    "\n",
    "y1 = beta01 + beta11*x1 + np.random.normal(size=300)\n",
    "y2 = beta02 + beta12*x2 + np.random.normal(size=600)\n",
    "\n",
    "x = np.concatenate([x1, x2])\n",
    "y = np.concatenate([y1, y2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EM convergence achieved] \n",
      "\n",
      "========================================================\n",
      "weights: [0.36165024 0.63834976]\n",
      "========================================================\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.956503\n",
      "         Iterations: 332\n",
      "         Function evaluations: 560\n",
      "                               Clusters Results                               \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   Log-Likelihood:                -1760.9\n",
      "Model:                       Clusters   AIC:                             3526.\n",
      "Method:            Maximum Likelihood   BIC:                             3535.\n",
      "Date:                Tue, 12 Mar 2019                                         \n",
      "Time:                        19:27:42                                         \n",
      "No. Observations:                 900                                         \n",
      "Df Residuals:                     898                                         \n",
      "Df Model:                           1                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const0         5.2586      0.150     35.043      0.000       4.964       5.553\n",
      "x10           -3.0802      0.048    -64.590      0.000      -3.174      -2.987\n",
      "const1         1.9527      0.089     21.851      0.000       1.778       2.128\n",
      "x11            3.0359      0.031     98.930      0.000       2.976       3.096\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "class Clusters(GenericLikelihoodModel):\n",
    "    \n",
    "    def __init__(self, endog, exog, ncomp=2):\n",
    "        super(Clusters, self).__init__(endog, exog)\n",
    "        \n",
    "        nobs, k = self.exog.shape\n",
    "        self.ncomp = ncomp\n",
    "        self.nparams = k*ncomp #hard coded for now\n",
    "        self.weights = np.ones(ncomp)/(1.*ncomp)\n",
    "\n",
    "        param_names = []\n",
    "        for comp in range(ncomp):\n",
    "            for name in self.data.xnames:\n",
    "                param_names.append(name+str(comp))\n",
    "        self.data.xnames = param_names\n",
    "        \n",
    "    \n",
    "    def nloglikeobs(self, params, v=False):\n",
    "        \"\"\"do maximum likelihood estimation\"\"\"\n",
    "        nobs, k = self.exog.shape\n",
    "        comp_likes = []\n",
    "        \n",
    "        for comp in range(self.ncomp):\n",
    "            \n",
    "            beta = params[2*comp: (k + 2*comp)]\n",
    "            beta = np.tile(beta,nobs).reshape(nobs, k)\n",
    "            resid = self.endog - (beta*self.exog).sum(axis=1)\n",
    "            \n",
    "            like = stats.norm.pdf(resid, loc=0, scale=1)\n",
    "            comp_likes.append(like)\n",
    "            \n",
    "            \n",
    "        weights = np.tile(self.weights, nobs).reshape(nobs, self.ncomp)\n",
    "        comp_likes = weights*np.array(comp_likes).transpose()\n",
    "        \n",
    "        return -np.log(comp_likes.sum(axis=1)).sum()\n",
    "    \n",
    "    \n",
    "    def fit(self, start_params=None, maxiter=1000, maxfun=5000, **kwds):\n",
    "        \"\"\"print that we did it\"\"\"\n",
    "        tol = 1e-10\n",
    "        nobs, k = self.exog.shape\n",
    "        \n",
    "        #loop variables\n",
    "        maxiter = 50\n",
    "        diff = 1\n",
    "        model = None\n",
    "        \n",
    "        while diff > tol and maxiter >=0 :\n",
    "            model = super(Clusters, self).fit(disp=False)\n",
    "            weights = []\n",
    "            \n",
    "            #recompute weights\n",
    "            for comp in range(self.ncomp):\n",
    "                beta = model.params[2*comp: (k + 2*comp)]\n",
    "                beta = np.tile(beta,nobs).reshape(nobs, k)\n",
    "                resid = self.endog - (beta*self.exog).sum(axis=1)\n",
    "                weights.append( stats.norm.pdf(resid, loc=0, scale=1).mean() )\n",
    "            \n",
    "            #update loop variables\n",
    "            weights = np.array(weights)/np.array(weights).sum()\n",
    "            diff = np.array(weights).mean()- self.weights.mean()\n",
    "            maxiter = maxiter-1\n",
    "            \n",
    "            self.weights = weights\n",
    "        \n",
    "        if maxiter > 0:\n",
    "            print '[EM convergence achieved] \\n'\n",
    "            print'========================================================'\n",
    "            print 'weights: %s'%self.weights\n",
    "            print'========================================================\\n'\n",
    "        \n",
    "        model = super(Clusters, self).fit()\n",
    "        return model\n",
    "        \n",
    "        \n",
    "model = Clusters(y,sm.add_constant(x))\n",
    "result = model.fit()\n",
    "\n",
    "print result.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
