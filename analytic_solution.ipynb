{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.base.model import GenericLikelihoodModel\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from scipy import cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "beta01, beta11 = 5,-3\n",
    "beta02, beta12 = 2, 4\n",
    "\n",
    "#set up regression mixture\n",
    "x1 = np.random.uniform(0, 10, size=400)\n",
    "x2 = np.random.uniform(0, 10, size=600)\n",
    "\n",
    "y1 = beta01 + beta11*x1 + np.random.normal(scale=5.0, size=400)\n",
    "y2 = beta02 + beta12*x2 + np.random.normal(scale=4.0,size=600)\n",
    "\n",
    "X = np.concatenate([x1, x2])\n",
    "Y = np.concatenate([y1, y2])\n",
    "\n",
    "\n",
    "#set up 2 component mixture\n",
    "a1 = np.random.normal(2, 5, size=600)\n",
    "a2 = np.random.normal(5, 3, size=400)\n",
    "a = np.concatenate([a1,a2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def e_step(y,x,params): \n",
    "    y, x = np.array(y), np.array(x)\n",
    "    nobs, k = x.shape\n",
    "    weights = []\n",
    "    for param in params:\n",
    "\n",
    "        sigma = param[-1]\n",
    "        beta = np.tile(param[1:-1],nobs).reshape(nobs, k)\n",
    "        mean = (beta*x).sum(axis=1)\n",
    "        weights.append( stats.norm.pdf(y, loc=mean, scale=sigma)*param[0] )\n",
    "        \n",
    "    #update loop variables\n",
    "    weights = np.array(weights).transpose()\n",
    "    #denom = np.repeat( 1+np.exp(weights).sum(axis=1), len(params) ).reshape(nobs,len(params))\n",
    "    denom = np.repeat(weights.sum(axis=1), len(params) ).reshape(nobs,len(params))\n",
    "    weights = weights/denom\n",
    "    return weights, np.log(denom[:,0])\n",
    "        \n",
    "    \n",
    "def m_step(y,x,weights):\n",
    "    y, x, weights = np.array(y), np.array(x), np.array(weights)\n",
    "    nobs, k = x.shape\n",
    "    params, se, err = [], [], 0\n",
    "\n",
    "    for w in weights.transpose():\n",
    "        \n",
    "        lamb = w.mean()\n",
    "        lamb_se = w.std()\n",
    "\n",
    "        #beta\n",
    "        w_mat = np.diag(w)\n",
    "        xx_mat = np.linalg.inv( x.transpose().dot( w_mat).dot(x) )\n",
    "        beta = xx_mat.dot(x.transpose().dot(w_mat)).dot(y)\n",
    "        \n",
    "        #sigma\n",
    "        mu = np.tile(beta, nobs).reshape(nobs, k)*x\n",
    "        weighted_err = w*(y - mu.sum(axis=1))**2\n",
    "        sigma =  (weighted_err.sum()/w.sum())**.5\n",
    "\n",
    "        #add component\n",
    "        comp_param =np.concatenate(([lamb],beta,[sigma]))\n",
    "        params.append(comp_param)\n",
    "\n",
    "        #beta_se\n",
    "        beta_se = (np.diagonal(xx_mat*sigma**2))**.5\n",
    "        comp_se = np.concatenate(([lamb_se],beta_se))\n",
    "        se.append(comp_se)\n",
    "\n",
    "        #SSR\n",
    "        err = err+weighted_err\n",
    "    return np.array(params), np.array(se), 1-err.mean()/y.var()\n",
    "\n",
    "\n",
    "def gen_weights(y,ncomp):\n",
    "    c,labels = cluster.vq.kmeans2(y,ncomp)\n",
    "    return np.array(pd.get_dummies(labels))\n",
    "\n",
    "\n",
    "def estimate(y,x,ncomp):\n",
    "    e = gen_weights(y,ncomp)\n",
    "    m = None\n",
    "    for i in range(20):\n",
    "        m,se,r2 = m_step(y,x,e)\n",
    "        e,ll = e_step(y,x,m)\n",
    "    return m, se, r2, y, x, ncomp, ll\n",
    "\n",
    "\n",
    "m, se, r2, y, x, ncomp, ll = estimate(Y, sm.add_constant(X), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_table(fname, estimates, labels=('y',None)):\n",
    "    \n",
    "    #unpack relevant information\n",
    "    params, se, r2, y, x, ncomp, ll = estimates\n",
    "    nobs, k = x.shape\n",
    "    ylabel, xlabel = labels\n",
    "    \n",
    "    if xlabel == None:\n",
    "        xlabel =[]\n",
    "        for i in range(k):\n",
    "            xlabel.append('x%s'%i)\n",
    "            \n",
    "    assert (k == len(xlabel)) \n",
    "    \n",
    "    f = open(fname, \"w+\")\n",
    "    \n",
    "    f.write(('\\\\begin{center}  \\n'+\n",
    "            '\\\\begin{tabular}{lclc} \\n'+\n",
    "            '\\\\toprule \\n'+\n",
    "            '\\\\textbf{Dep. Variable:} & %s & \\\\textbf{  R-squared: } &  %s \\\\\\\\ \\n'%(ylabel, np.round(r2,3))  ))\n",
    "    \n",
    "    f.write(('\\\\textbf{No. Observations:} & %s & \\\\textbf{ Log-Likelihood:} & %s \\\\\\\\ \\n'%(nobs,\n",
    "                                                                                           np.round(ll.sum(),1))+\n",
    "            '\\end{tabular} \\n'))\n",
    "    \n",
    "    \n",
    "    f.write('\\n\\\\begin{tabular}{lcccc} \\n')\n",
    "    for comp in range(ncomp):\n",
    "        f.write('\\\\toprule \\n')\n",
    "        f.write('\\\\textbf{Regime %s} & \\\\textbf{est} & \\\\textbf{std err} &'%(1+comp)+ \n",
    "                '\\\\textbf{t} & \\\\textbf{P $>$ $|$ t $|$} \\\\\\\\ \\n')\n",
    "        f.write('\\\\bottomrule \\\\\\\\ \\n')\n",
    "        \n",
    "        #isolate params\n",
    "        comp_params = params[comp]\n",
    "        comp_se = se[comp]\n",
    "        comp_t = comp_params[:-1]/comp_se\n",
    "        comp_p = 1 - stats.t.cdf(np.abs(comp_t),df=(nobs-k)) + stats.t.cdf(-np.abs(comp_t),df=(nobs-k))\n",
    "        \n",
    "        #round everything\n",
    "        comp_params = np.round(comp_params,5)\n",
    "        comp_se = np.round(comp_se,5)\n",
    "        comp_t = np.round(comp_t,5)\n",
    "        comp_p = np.round(comp_p,5)\n",
    "        \n",
    "        lamb = comp_params[0]\n",
    "        #lamb_se, lamb_t, lamb_p = comp_params[0], comp_se[0], comp_t[0], comp_p[0]\n",
    "        beta, beta_se, beta_t, beta_p = comp_params[1:-1], comp_se[1:], comp_t[1:], comp_p[1:]\n",
    "        sigma = comp_params[-1]\n",
    "        \n",
    "        if ncomp > 1:\n",
    "            f.write('\\\\textbf{lambda} & %s  & & & \\\\\\\\ \\\\\\\\ \\n'%(lamb) )\n",
    "        \n",
    "        for i in range(k):\n",
    "            f.write('\\\\textbf{%s} & %s & (%s) & %s & %s \\\\\\\\ \\\\\\\\ \\n'%(xlabel[i],beta[i],beta_se[i],\n",
    "                                                                             beta_t[i],beta_p[i]) )\n",
    "        \n",
    "        f.write('\\\\textbf{sigma} & %s &  & & \\\\\\\\ \\\\\\\\ \\n'%(sigma) )\n",
    "    \n",
    "    f.write('\\end{tabular} \\n'+\n",
    "            '\\end{center}\\n')\n",
    "    f.close()\n",
    "    \n",
    "    #print output\n",
    "    f = open(fname, \"r\")\n",
    "    print f.read()\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'Unnamed: 0', u'YEAR', u'MONTH', u'DAY', u'SYSTEM', u'FMOZONE',\n",
      "       u'VENDOR', u'COUNTY', u'LWW', u'LFMO', u'LGAS', u'LPOPUL', u'LQWW',\n",
      "       u'LMEALS', u'COOLER', u'ESC', u'1A', u'3', u'6', u'7', u'9', u'INC',\n",
      "       u'LWW_min1', u'LWW_min2', u'LWW_min3', u'LWW_max1', u'LWW_max2',\n",
      "       u'LWW_max3'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "reg1 = pd.read_csv('data/clean_milk1.csv')\n",
    "print reg1.columns\n",
    "\n",
    "#variables names\n",
    "lmilk = ['LWW']\n",
    "auct_key = ['YEAR','MONTH','DAY','SYSTEM','FMOZONE']\n",
    "lcts = ['LFMO','LGAS','LPOPUL','LQWW','LMEALS']\n",
    "dummies = ['COOLER','ESC']\n",
    "fekeys = ['1A', '3', '6', '7', '9']\n",
    "\n",
    "lags = 3\n",
    "lagkeys = [l+str(i) for l in ['LWW_min','LWW_max'] for i in range(1,1+lags)]\n",
    "\n",
    "bid_key = auct_key + ['VENDOR'] + ['COUNTY']\n",
    "covariates = lcts + dummies + fekeys\n",
    "hist = ['INC'] + lagkeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{center}  \n",
      "\\begin{tabular}{lclc} \n",
      "\\toprule \n",
      "\\textbf{Dep. Variable:} & LWW & \\textbf{  R-squared: } &  0.185 \\\\ \n",
      "\\textbf{No. Observations:} & 3665 & \\textbf{ Log-Likelihood:} & 4073.6 \\\\ \n",
      "\\end{tabular} \n",
      "\n",
      "\\begin{tabular}{lcccc} \n",
      "\\toprule \n",
      "\\textbf{Regime 1} & \\textbf{est} & \\textbf{std err} &\\textbf{t} & \\textbf{P $>$ $|$ t $|$} \\\\ \n",
      "\\bottomrule \\\\ \n",
      "\\textbf{const} & -2.26908 & (0.072) & -31.51664 & 0.0 \\\\ \\\\ \n",
      "\\textbf{LFMO} & 0.20991 & (0.02617) & 8.02093 & 0.0 \\\\ \\\\ \n",
      "\\textbf{LGAS} & 0.00918 & (0.00409) & 2.2428 & 0.02497 \\\\ \\\\ \n",
      "\\textbf{LPOPUL} & 0.02545 & (0.00315) & 8.09203 & 0.0 \\\\ \\\\ \n",
      "\\textbf{LQWW} & -0.00012 & (0.00204) & -0.05959 & 0.95248 \\\\ \\\\ \n",
      "\\textbf{LMEALS} & -0.02269 & (0.00306) & -7.40151 & 0.0 \\\\ \\\\ \n",
      "\\textbf{COOLER} & 0.01777 & (0.00296) & 6.00939 & 0.0 \\\\ \\\\ \n",
      "\\textbf{ESC} & -0.01976 & (0.00279) & -7.07503 & 0.0 \\\\ \\\\ \n",
      "\\textbf{1A} & -0.02458 & (0.01893) & -1.29838 & 0.19424 \\\\ \\\\ \n",
      "\\textbf{3} & -0.06477 & (0.0042) & -15.41156 & 0.0 \\\\ \\\\ \n",
      "\\textbf{6} & -0.05256 & (0.00803) & -6.5459 & 0.0 \\\\ \\\\ \n",
      "\\textbf{7} & -0.11168 & (0.01757) & -6.3561 & 0.0 \\\\ \\\\ \n",
      "\\textbf{9} & -0.0334 & (0.00447) & -7.47119 & 0.0 \\\\ \\\\ \n",
      "\\textbf{sigma} & 0.07963 &  & & \\\\ \\\\ \n",
      "\\end{tabular} \n",
      "\\end{center}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erichschulman/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:37: RuntimeWarning: divide by zero encountered in divide\n"
     ]
    }
   ],
   "source": [
    "est0 = estimate(reg1['LWW'],sm.add_constant(reg1[covariates]),1)\n",
    "write_table('results/ols_results.tex', est0, labels=('LWW', ['const']+covariates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{center}  \n",
      "\\begin{tabular}{lclc} \n",
      "\\toprule \n",
      "\\textbf{Dep. Variable:} & LWW & \\textbf{  R-squared: } &  0.211 \\\\ \n",
      "\\textbf{No. Observations:} & 3665 & \\textbf{ Log-Likelihood:} & 4134.1 \\\\ \n",
      "\\end{tabular} \n",
      "\n",
      "\\begin{tabular}{lcccc} \n",
      "\\toprule \n",
      "\\textbf{Regime 1} & \\textbf{est} & \\textbf{std err} &\\textbf{t} & \\textbf{P $>$ $|$ t $|$} \\\\ \n",
      "\\bottomrule \\\\ \n",
      "\\textbf{const} & -1.68047 & (0.09641) & -17.43104 & 0.0 \\\\ \\\\ \n",
      "\\textbf{LFMO} & 0.15998 & (0.0263) & 6.08293 & 0.0 \\\\ \\\\ \n",
      "\\textbf{LGAS} & 0.01015 & (0.00406) & 2.50293 & 0.01236 \\\\ \\\\ \n",
      "\\textbf{LPOPUL} & 0.02095 & (0.00314) & 6.67031 & 0.0 \\\\ \\\\ \n",
      "\\textbf{LQWW} & 0.0016 & (0.00204) & 0.78401 & 0.43309 \\\\ \\\\ \n",
      "\\textbf{LMEALS} & -0.02066 & (0.00304) & -6.80183 & 0.0 \\\\ \\\\ \n",
      "\\textbf{COOLER} & 0.01863 & (0.00293) & 6.35513 & 0.0 \\\\ \\\\ \n",
      "\\textbf{ESC} & -0.01905 & (0.00275) & -6.91821 & 0.0 \\\\ \\\\ \n",
      "\\textbf{1A} & -0.01497 & (0.01869) & -0.8011 & 0.42313 \\\\ \\\\ \n",
      "\\textbf{3} & -0.06531 & (0.00414) & -15.77324 & 0.0 \\\\ \\\\ \n",
      "\\textbf{6} & -0.05735 & (0.00794) & -7.22304 & 0.0 \\\\ \\\\ \n",
      "\\textbf{7} & -0.12646 & (0.01735) & -7.28761 & 0.0 \\\\ \\\\ \n",
      "\\textbf{9} & -0.03542 & (0.00441) & -8.02843 & 0.0 \\\\ \\\\ \n",
      "\\textbf{INC} & 0.03061 & (0.00658) & 4.65461 & 0.0 \\\\ \\\\ \n",
      "\\textbf{LWW_min1} & -0.01032 & (0.01903) & -0.54203 & 0.58783 \\\\ \\\\ \n",
      "\\textbf{LWW_min2} & 0.04548 & (0.01898) & 2.39545 & 0.01665 \\\\ \\\\ \n",
      "\\textbf{LWW_min3} & 0.04384 & (0.01908) & 2.29712 & 0.02167 \\\\ \\\\ \n",
      "\\textbf{LWW_max1} & 0.11537 & (0.01885) & 6.12191 & 0.0 \\\\ \\\\ \n",
      "\\textbf{LWW_max2} & 0.02735 & (0.01855) & 1.47464 & 0.1404 \\\\ \\\\ \n",
      "\\textbf{LWW_max3} & 0.04362 & (0.01844) & 2.36499 & 0.01808 \\\\ \\\\ \n",
      "\\textbf{sigma} & 0.07832 &  & & \\\\ \\\\ \n",
      "\\end{tabular} \n",
      "\\end{center}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erichschulman/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:37: RuntimeWarning: divide by zero encountered in divide\n"
     ]
    }
   ],
   "source": [
    "est1 = estimate(reg1['LWW'],sm.add_constant(reg1[covariates + hist]),1)\n",
    "write_table('results/hist_results.tex', est1, labels=('LWW', ['const']+covariates + hist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{center}  \n",
      "\\begin{tabular}{lclc} \n",
      "\\toprule \n",
      "\\textbf{Dep. Variable:} & LWW & \\textbf{  R-squared: } &  0.439 \\\\ \n",
      "\\textbf{No. Observations:} & 3665 & \\textbf{ Log-Likelihood:} & 4401.4 \\\\ \n",
      "\\end{tabular} \n",
      "\n",
      "\\begin{tabular}{lcccc} \n",
      "\\toprule \n",
      "\\textbf{Regime 1} & \\textbf{est} & \\textbf{std err} &\\textbf{t} & \\textbf{P $>$ $|$ t $|$} \\\\ \n",
      "\\bottomrule \\\\ \n",
      "\\textbf{lambda} & 0.6813  & & & \\\\ \\\\ \n",
      "\\textbf{const} & -2.14093 & (0.0836) & -25.60835 & 0.0 \\\\ \\\\ \n",
      "\\textbf{LFMO} & 0.19306 & (0.03017) & 6.39825 & 0.0 \\\\ \\\\ \n",
      "\\textbf{LGAS} & -0.00927 & (0.00471) & -1.9654 & 0.04944 \\\\ \\\\ \n",
      "\\textbf{LPOPUL} & 0.03933 & (0.00406) & 9.69727 & 0.0 \\\\ \\\\ \n",
      "\\textbf{LQWW} & 0.00104 & (0.00229) & 0.45271 & 0.65078 \\\\ \\\\ \n",
      "\\textbf{LMEALS} & -0.03515 & (0.00394) & -8.92843 & 0.0 \\\\ \\\\ \n",
      "\\textbf{COOLER} & 0.01836 & (0.00342) & 5.37041 & 0.0 \\\\ \\\\ \n",
      "\\textbf{ESC} & -0.01932 & (0.00329) & -5.87378 & 0.0 \\\\ \\\\ \n",
      "\\textbf{1A} & -0.0401 & (0.02407) & -1.66591 & 0.09582 \\\\ \\\\ \n",
      "\\textbf{3} & -0.02197 & (0.00478) & -4.5951 & 0.0 \\\\ \\\\ \n",
      "\\textbf{6} & -0.01692 & (0.00916) & -1.84715 & 0.06481 \\\\ \\\\ \n",
      "\\textbf{7} & -0.01678 & (0.02267) & -0.7402 & 0.45923 \\\\ \\\\ \n",
      "\\textbf{9} & 0.01589 & (0.00505) & 3.14517 & 0.00167 \\\\ \\\\ \n",
      "\\textbf{sigma} & 0.07644 &  & & \\\\ \\\\ \n",
      "\\toprule \n",
      "\\textbf{Regime 2} & \\textbf{est} & \\textbf{std err} &\\textbf{t} & \\textbf{P $>$ $|$ t $|$} \\\\ \n",
      "\\bottomrule \\\\ \n",
      "\\textbf{lambda} & 0.3187  & & & \\\\ \\\\ \n",
      "\\textbf{const} & -2.72517 & (0.05622) & -48.47507 & 0.0 \\\\ \\\\ \n",
      "\\textbf{LFMO} & 0.3563 & (0.02064) & 17.25905 & 0.0 \\\\ \\\\ \n",
      "\\textbf{LGAS} & 0.00266 & (0.00328) & 0.80933 & 0.41838 \\\\ \\\\ \n",
      "\\textbf{LPOPUL} & -0.00181 & (0.00208) & -0.87022 & 0.38424 \\\\ \\\\ \n",
      "\\textbf{LQWW} & 0.00671 & (0.00175) & 3.84324 & 0.00012 \\\\ \\\\ \n",
      "\\textbf{LMEALS} & -0.0043 & (0.00206) & -2.09007 & 0.03668 \\\\ \\\\ \n",
      "\\textbf{COOLER} & 0.00266 & (0.00231) & 1.15254 & 0.24917 \\\\ \\\\ \n",
      "\\textbf{ESC} & -0.00451 & (0.00212) & -2.1303 & 0.03321 \\\\ \\\\ \n",
      "\\textbf{1A} & -0.00479 & (0.01252) & -0.38295 & 0.70178 \\\\ \\\\ \n",
      "\\textbf{3} & -0.18005 & (0.00345) & -52.19807 & 0.0 \\\\ \\\\ \n",
      "\\textbf{6} & -0.13706 & (0.00645) & -21.2453 & 0.0 \\\\ \\\\ \n",
      "\\textbf{7} & -0.23857 & (0.01147) & -20.802 & 0.0 \\\\ \\\\ \n",
      "\\textbf{9} & -0.19796 & (0.00383) & -51.6442 & 0.0 \\\\ \\\\ \n",
      "\\textbf{sigma} & 0.03446 &  & & \\\\ \\\\ \n",
      "\\end{tabular} \n",
      "\\end{center}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "est2 = estimate(reg1['LWW'],sm.add_constant(reg1[covariates]),2)\n",
    "write_table('results/prelim_results.tex', est2, labels=('LWW', ['const']+covariates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8.897585376501732, 8.79719221044862, 4.422054637877961e-19, 1.0663536269065003e-18)\n"
     ]
    }
   ],
   "source": [
    "test1 = estimate(Y, sm.add_constant(X), 2)\n",
    "test2 = estimate(Y, sm.add_constant(X), 1)\n",
    "\n",
    "def nonnested_test(model1,model2):\n",
    "    \"\"\"test for non nested models quang vuong\"\"\"\n",
    "    \n",
    "    params1, se1, r21, y1, x1, ncomp1, ll1 = model1\n",
    "    params2, se2, r22, y2, x2, ncomp2, ll2 = model2\n",
    "    nobs, k = x1.shape\n",
    "    \n",
    "    k1 = params1.shape[1]*ncomp1 - 1 \n",
    "    k2 = params2.shape[1]*ncomp2 - 1\n",
    "    \n",
    "    var1 = (ll1 -ll2).std()\n",
    "    test1 = (ll1.sum() - ll2.sum() - k1 + k2)*nobs**(-.5)\n",
    "    test1 = test1/var1\n",
    "    p1 = 1 - stats.t.cdf(np.abs(test1),df=(nobs-k1-k2)) + stats.t.cdf(-np.abs(test1),df=(nobs-k1-k2))\n",
    "    \n",
    "    var2 =  ((ll1 - ll2)**2).mean()**.5\n",
    "    test2 = (ll1.sum() - ll2.sum() - k1 + k2 )*nobs**(-.5)\n",
    "    test2 = test2/var2\n",
    "    p2 = 1 - stats.t.cdf(np.abs(test2),df=(nobs-k1-k2)) + stats.t.cdf(-np.abs(test2),df=(nobs-k1-k2))\n",
    "    \n",
    "    f.write(('\\\\begin{center}  \\n'+\n",
    "            '\\\\begin{tabular}{lclc} \\n'+\n",
    "            '\\\\toprule \\n'+\n",
    "            '\\\\textbf{Dep. Variable:} & %s & \\\\textbf{  R-squared: } &  %s \\\\\\\\ \\n'%(ylabel, np.round(r2,3))  ))\n",
    "    \n",
    "    f.write(('\\\\textbf{No. Observations:} & %s & \\\\textbf{ Log-Likelihood:} & %s \\\\\\\\ \\n'%(nobs,\n",
    "                                                                                          np.round(ll.sum(),1))+\n",
    "            '\\end{tabular} \\n'))\n",
    "    \n",
    "    \n",
    "    \n",
    "    #f.write('\\end{tabular} \\n'+\n",
    "    #        '\\end{center}\\n')\n",
    "    #f.close()\n",
    "    \n",
    "    return test1, test2, p1, p2\n",
    "\n",
    "print nonnested_test(est2,est1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
