{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.base.model import GenericLikelihoodModel\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from scipy import cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "beta01, beta11 = 5,-3\n",
    "beta02, beta12 = 2, 4\n",
    "\n",
    "#set up regression mixture\n",
    "x1 = np.random.uniform(0, 10, size=400)\n",
    "x2 = np.random.uniform(0, 10, size=600)\n",
    "\n",
    "y1 = beta01 + beta11*x1 + np.random.normal(scale=5.0, size=400)\n",
    "y2 = beta02 + beta12*x2 + np.random.normal(scale=4.0,size=600)\n",
    "\n",
    "X = np.concatenate([x1, x2])\n",
    "Y = np.concatenate([y1, y2])\n",
    "\n",
    "\n",
    "#set up 2 component mixture\n",
    "a1 = np.random.normal(2, 5, size=600)\n",
    "a2 = np.random.normal(5, 3, size=400)\n",
    "a = np.concatenate([a1,a2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def e_step(y,x,params): \n",
    "    y, x = np.array(y), np.array(x)\n",
    "    nobs, k = x.shape\n",
    "    weights = []\n",
    "    for param in params:\n",
    "\n",
    "        sigma = param[-1]\n",
    "        beta = np.tile(param[1:-1],nobs).reshape(nobs, k)\n",
    "        mean = (beta*x).sum(axis=1)\n",
    "        weights.append( stats.norm.pdf(y, loc=mean, scale=sigma)*param[0] )\n",
    "        \n",
    "    #update loop variables\n",
    "    weights = np.array(weights).transpose()\n",
    "    #denom = np.repeat( 1+np.exp(weights).sum(axis=1), len(params) ).reshape(nobs,len(params))\n",
    "    denom = np.repeat(weights.sum(axis=1), len(params) ).reshape(nobs,len(params))\n",
    "    weights = weights/denom\n",
    "    return weights, np.log(denom[:,0])\n",
    "        \n",
    "    \n",
    "def m_step(y,x,weights):\n",
    "    y, x, weights = np.array(y), np.array(x), np.array(weights)\n",
    "    nobs, k = x.shape\n",
    "    params, se, err = [], [], 0\n",
    "\n",
    "    for w in weights.transpose():\n",
    "        \n",
    "        lamb = w.mean()\n",
    "        lamb_se = w.std()\n",
    "\n",
    "        #beta\n",
    "        w_mat = np.diag(w)\n",
    "        xx_mat = np.linalg.inv( x.transpose().dot( w_mat).dot(x) )\n",
    "        beta = xx_mat.dot(x.transpose().dot(w_mat)).dot(y)\n",
    "        \n",
    "        #sigma\n",
    "        mu = np.tile(beta, nobs).reshape(nobs, k)*x\n",
    "        weighted_err = w*(y - mu.sum(axis=1))**2\n",
    "        sigma =  (weighted_err.sum()/w.sum())**.5\n",
    "\n",
    "        #add component\n",
    "        comp_param =np.concatenate(([lamb],beta,[sigma]))\n",
    "        params.append(comp_param)\n",
    "\n",
    "        #beta_se\n",
    "        beta_se = (np.diagonal(xx_mat*sigma**2))**.5\n",
    "        comp_se = np.concatenate(([lamb_se],beta_se))\n",
    "        se.append(comp_se)\n",
    "\n",
    "        #SSR\n",
    "        err = err+weighted_err\n",
    "    return np.array(params), np.array(se), 1-err.mean()/y.var()\n",
    "\n",
    "\n",
    "def gen_weights(y,ncomp):\n",
    "    c,labels = cluster.vq.kmeans2(y,ncomp)\n",
    "    return np.array(pd.get_dummies(labels))\n",
    "\n",
    "\n",
    "def estimate(y,x,ncomp):\n",
    "    e = gen_weights(y,ncomp)\n",
    "    m = None\n",
    "    for i in range(20):\n",
    "        m,se,r2 = m_step(y,x,e)\n",
    "        e,ll = e_step(y,x,m)\n",
    "    return m, se, r2, y, x, ncomp, ll\n",
    "\n",
    "\n",
    "m, se, r2, y, x, ncomp, ll = estimate(Y, sm.add_constant(X), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_table(fname, estimates, labels=('y',None)):\n",
    "    \n",
    "    #unpack relevant information\n",
    "    params, se, r2, y, x, ncomp, ll = estimates\n",
    "    nobs, k = x.shape\n",
    "    ylabel, xlabel = labels\n",
    "    \n",
    "    #calc aic\n",
    "    aic = 2*(params.shape[0]*params.shape[1]-2) - 2*ll.sum()\n",
    "    aic = np.round(aic,1)\n",
    "    \n",
    "    if xlabel == None:\n",
    "        xlabel =[]\n",
    "        for i in range(k):\n",
    "            xlabel.append('x%s'%i)\n",
    "            \n",
    "    assert (k == len(xlabel)) \n",
    "    \n",
    "    f = open(fname, \"w+\")\n",
    "    \n",
    "    f.write(('\\\\small \\n'+\n",
    "            '\\\\begin{tabular}{lclc} \\n'+\n",
    "            '\\\\hline \\n'+\n",
    "            '\\\\textbf{Dep. Variable:} & %s & \\\\textbf{  R-squared: } &  %s \\\\\\\\ \\n'%(ylabel, np.round(r2,3))  ))\n",
    "    \n",
    "    f.write(('\\\\textbf{No. Observations:} & %s & \\\\textbf{ AIC:} & %s \\\\\\\\ \\n'%(nobs,aic)+\n",
    "                                                                                    \n",
    "            '\\end{tabular} \\n'))\n",
    "    \n",
    "    \n",
    "    f.write('\\n\\\\begin{tabular}{lcccc} \\n')\n",
    "    for comp in range(ncomp):\n",
    "        f.write('\\\\hline \\n')\n",
    "        f.write('\\\\textbf{Phase %s} & \\\\textbf{Est.} & \\\\textbf{Std. Err.} &'%(1+comp)+ \n",
    "                '\\\\textbf{t} & \\\\textbf{P $>$ $|$ t $|$} \\\\\\\\ \\n')\n",
    "        f.write('\\\\hline \\\\\\\\ \\n')\n",
    "        \n",
    "        #isolate params\n",
    "        comp_params = params[comp]\n",
    "        comp_se = se[comp]\n",
    "        comp_t = comp_params[:-1]/comp_se\n",
    "        comp_p = 1 - stats.t.cdf(np.abs(comp_t),df=(nobs-k)) + stats.t.cdf(-np.abs(comp_t),df=(nobs-k))\n",
    "        \n",
    "        #round everything\n",
    "        comp_params = np.round(comp_params,5)\n",
    "        comp_se = np.round(comp_se,5)\n",
    "        comp_t = np.round(comp_t,5)\n",
    "        comp_p = np.round(comp_p,5)\n",
    "        \n",
    "        lamb, lamb_se = comp_params[0], comp_se[0]\n",
    "        #lamb_t, lamb_p = comp_params[0],  comp_t[0], comp_p[0]\n",
    "        beta, beta_se, beta_t, beta_p = comp_params[1:-1], comp_se[1:], comp_t[1:], comp_p[1:]\n",
    "        sigma = comp_params[-1]\n",
    "        \n",
    "        if ncomp > 1:\n",
    "            f.write('\\\\textbf{Pr(phase %s)} & %s  & %s & & \\\\\\\\ \\\\\\\\ \\n'%(comp+1, lamb, lamb_se) )\n",
    "        \n",
    "        for i in range(k):\n",
    "            f.write('\\\\textbf{%s} & %s & (%s) & %s & %s \\\\\\\\ \\\\\\\\ \\n'%(xlabel[i],beta[i],beta_se[i],\n",
    "                                                                             beta_t[i],beta_p[i]) )\n",
    "        \n",
    "        #f.write('\\\\textbf{Variance} & %s &  & & \\\\\\\\ \\\\\\\\ \\n'%(sigma) )\n",
    "    f.write('\\\\hline \\\\\\\\ \\n')    \n",
    "    f.write('\\end{tabular} \\n')\n",
    "    f.close()\n",
    "    \n",
    "    #print output\n",
    "    f = open(fname, \"r\")\n",
    "    print f.read()\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'Unnamed: 0', u'YEAR', u'MONTH', u'DAY', u'SYSTEM', u'FMOZONE',\n",
      "       u'VENDOR', u'COUNTY', u'LWW', u'LFMO', u'LGAS', u'LPOPUL', u'LQWW',\n",
      "       u'COOLER', u'ESC', u'3', u'6', u'7', u'9', u'INC', u'LWW_min1',\n",
      "       u'LWW_min2', u'LWW_min3', u'LWW_min4', u'LWW_max1', u'LWW_max2',\n",
      "       u'LWW_max3', u'LWW_max4'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "reg1 = pd.read_csv('data/clean_milk1.csv')\n",
    "print reg1.columns\n",
    "\n",
    "#variables names\n",
    "lmilk = ['LWW']\n",
    "auct_key = ['YEAR','MONTH','DAY','SYSTEM','FMOZONE']\n",
    "lcts = ['LFMO','LGAS','LPOPUL','LQWW']#,'LMEALS']\n",
    "dummies = ['COOLER','ESC']\n",
    "\n",
    "fekeys = list(reg1.columns[15:-9])\n",
    "\n",
    "\n",
    "lags = 4\n",
    "lagkeys = [l+str(i) for l in ['LWW_min','LWW_max'] for i in range(1,1+lags)]\n",
    "\n",
    "bid_key = auct_key + ['VENDOR'] + ['COUNTY']\n",
    "covariates = lcts + dummies + fekeys\n",
    "hist = ['INC'] + lagkeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "nice_ww = 'Bids (log-log)'\n",
    "nice_cov = ['(Intercept)', 'Raw milk', 'Gas',\n",
    "            'Population', 'Quantity', #'Meals',\n",
    "            'Cooler', 'Escalated', #+ fekeys\n",
    "            'Waco','St. Angelo', 'Austin', 'San Antonio']\n",
    "nice_lags = [l+str(i) for l in ['Min. lag \\#','Max. lag \\#'] for i in range(1,1+lags)]\n",
    "nice_lags = ['Incumbency'] + nice_lags\n",
    "\n",
    "print len(nice_cov)\n",
    "print len(covariates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\small \n",
      "\\begin{tabular}{lclc} \n",
      "\\hline \n",
      "\\textbf{Dep. Variable:} & Bids (log-log) & \\textbf{  R-squared: } &  0.158 \\\\ \n",
      "\\textbf{No. Observations:} & 3823 & \\textbf{ AIC:} & -8399.7 \\\\ \n",
      "\\end{tabular} \n",
      "\n",
      "\\begin{tabular}{lcccc} \n",
      "\\hline \n",
      "\\textbf{Phase 1} & \\textbf{Est.} & \\textbf{Std. Err.} &\\textbf{t} & \\textbf{P $>$ $|$ t $|$} \\\\ \n",
      "\\hline \\\\ \n",
      "\\textbf{(Intercept)} & -2.32583 & (0.07014) & -33.15816 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Raw milk} & 0.18546 & (0.02613) & 7.09658 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Gas} & 0.01672 & (0.00401) & 4.16971 & 3e-05 \\\\ \\\\ \n",
      "\\textbf{Population} & 0.00709 & (0.00184) & 3.84354 & 0.00012 \\\\ \\\\ \n",
      "\\textbf{Quantity} & -0.00354 & (0.002) & -1.77142 & 0.07657 \\\\ \\\\ \n",
      "\\textbf{Cooler} & 0.01847 & (0.00292) & 6.32972 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Escalated} & -0.0229 & (0.00274) & -8.34616 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Waco} & -0.06712 & (0.00412) & -16.30108 & 0.0 \\\\ \\\\ \n",
      "\\textbf{St. Angelo} & -0.05418 & (0.00807) & -6.71672 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Austin} & -0.08556 & (0.01378) & -6.2108 & 0.0 \\\\ \\\\ \n",
      "\\textbf{San Antonio} & -0.0424 & (0.0042) & -10.10292 & 0.0 \\\\ \\\\ \n",
      "\\hline \\\\ \n",
      "\\end{tabular} \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erichschulman/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:41: RuntimeWarning: divide by zero encountered in divide\n"
     ]
    }
   ],
   "source": [
    "est0 = estimate(reg1['LWW'],sm.add_constant(reg1[covariates]),1)\n",
    "write_table('results/ols_results.tex', est0, labels=(nice_ww, nice_cov))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\small \n",
      "\\begin{tabular}{lclc} \n",
      "\\hline \n",
      "\\textbf{Dep. Variable:} & Bids (log-log) & \\textbf{  R-squared: } &  0.195 \\\\ \n",
      "\\textbf{No. Observations:} & 3823 & \\textbf{ AIC:} & -8552.5 \\\\ \n",
      "\\end{tabular} \n",
      "\n",
      "\\begin{tabular}{lcccc} \n",
      "\\hline \n",
      "\\textbf{Phase 1} & \\textbf{Est.} & \\textbf{Std. Err.} &\\textbf{t} & \\textbf{P $>$ $|$ t $|$} \\\\ \n",
      "\\hline \\\\ \n",
      "\\textbf{(Intercept)} & -1.5375 & (0.09889) & -15.54688 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Raw milk} & 0.1245 & (0.02614) & 4.76353 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Gas} & 0.01666 & (0.00396) & 4.20662 & 3e-05 \\\\ \\\\ \n",
      "\\textbf{Population} & 0.00376 & (0.00185) & 2.02919 & 0.04251 \\\\ \\\\ \n",
      "\\textbf{Quantity} & -0.00135 & (0.00199) & -0.67705 & 0.49842 \\\\ \\\\ \n",
      "\\textbf{Cooler} & 0.01833 & (0.00287) & 6.38353 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Escalated} & -0.0219 & (0.00269) & -8.13833 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Waco} & -0.06922 & (0.00404) & -17.12198 & 0.0 \\\\ \\\\ \n",
      "\\textbf{St. Angelo} & -0.05885 & (0.00793) & -7.42203 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Austin} & -0.09643 & (0.01352) & -7.13092 & 0.0 \\\\ \\\\ \n",
      "\\textbf{San Antonio} & -0.04592 & (0.00415) & -11.05574 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Incumbency} & 0.02601 & (0.00554) & 4.69101 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Min. lag \\#1} & -0.00736 & (0.01894) & -0.38842 & 0.69772 \\\\ \\\\ \n",
      "\\textbf{Min. lag \\#2} & 0.05713 & (0.01884) & 3.03269 & 0.00244 \\\\ \\\\ \n",
      "\\textbf{Min. lag \\#3} & 0.04689 & (0.01901) & 2.46737 & 0.01365 \\\\ \\\\ \n",
      "\\textbf{Min. lag \\#4} & 0.0253 & (0.01883) & 1.34353 & 0.17918 \\\\ \\\\ \n",
      "\\textbf{Max. lag \\#1} & 0.12466 & (0.01864) & 6.68701 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Max. lag \\#2} & 0.02557 & (0.01843) & 1.38693 & 0.16554 \\\\ \\\\ \n",
      "\\textbf{Max. lag \\#3} & 0.04625 & (0.01844) & 2.50852 & 0.01217 \\\\ \\\\ \n",
      "\\textbf{Max. lag \\#4} & 0.03404 & (0.01791) & 1.90053 & 0.05744 \\\\ \\\\ \n",
      "\\hline \\\\ \n",
      "\\end{tabular} \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erichschulman/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:41: RuntimeWarning: divide by zero encountered in divide\n"
     ]
    }
   ],
   "source": [
    "est1 = estimate(reg1['LWW'],sm.add_constant(reg1[covariates + hist]),1)\n",
    "write_table('results/hist_results.tex', est1, labels=(nice_ww, nice_cov + nice_lags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\small \n",
      "\\begin{tabular}{lclc} \n",
      "\\hline \n",
      "\\textbf{Dep. Variable:} & Bids (log-log) & \\textbf{  R-squared: } &  0.41 \\\\ \n",
      "\\textbf{No. Observations:} & 3823 & \\textbf{ AIC:} & -9004.1 \\\\ \n",
      "\\end{tabular} \n",
      "\n",
      "\\begin{tabular}{lcccc} \n",
      "\\hline \n",
      "\\textbf{Phase 1} & \\textbf{Est.} & \\textbf{Std. Err.} &\\textbf{t} & \\textbf{P $>$ $|$ t $|$} \\\\ \n",
      "\\hline \\\\ \n",
      "\\textbf{Pr(phase 1)} & 0.31328  & 0.25513 & & \\\\ \\\\ \n",
      "\\textbf{(Intercept)} & -2.72138 & (0.05916) & -46.00008 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Raw milk} & 0.34896 & (0.02199) & 15.87006 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Gas} & 0.00668 & (0.00349) & 1.91691 & 0.05532 \\\\ \\\\ \n",
      "\\textbf{Population} & -0.00347 & (0.00168) & -2.06565 & 0.03893 \\\\ \\\\ \n",
      "\\textbf{Quantity} & 0.00327 & (0.00184) & 1.77861 & 0.07538 \\\\ \\\\ \n",
      "\\textbf{Cooler} & 0.00408 & (0.00247) & 1.654 & 0.09821 \\\\ \\\\ \n",
      "\\textbf{Escalated} & -0.00487 & (0.00225) & -2.1645 & 0.03049 \\\\ \\\\ \n",
      "\\textbf{Waco} & -0.17572 & (0.00362) & -48.55432 & 0.0 \\\\ \\\\ \n",
      "\\textbf{St. Angelo} & -0.13892 & (0.00681) & -20.39945 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Austin} & -0.2252 & (0.01094) & -20.57839 & 0.0 \\\\ \\\\ \n",
      "\\textbf{San Antonio} & -0.19527 & (0.00385) & -50.7841 & 0.0 \\\\ \\\\ \n",
      "\\hline \n",
      "\\textbf{Phase 2} & \\textbf{Est.} & \\textbf{Std. Err.} &\\textbf{t} & \\textbf{P $>$ $|$ t $|$} \\\\ \n",
      "\\hline \\\\ \n",
      "\\textbf{Pr(phase 2)} & 0.68672  & 0.25513 & & \\\\ \\\\ \n",
      "\\textbf{(Intercept)} & -2.22754 & (0.08084) & -27.55524 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Raw milk} & 0.15383 & (0.03016) & 5.09963 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Gas} & 4e-05 & (0.00459) & 0.00917 & 0.99269 \\\\ \\\\ \n",
      "\\textbf{Population} & 0.00894 & (0.00207) & 4.32674 & 2e-05 \\\\ \\\\ \n",
      "\\textbf{Quantity} & -0.00198 & (0.00223) & -0.88743 & 0.3749 \\\\ \\\\ \n",
      "\\textbf{Cooler} & 0.01877 & (0.00336) & 5.58808 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Escalated} & -0.02396 & (0.00321) & -7.45704 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Waco} & -0.02656 & (0.00467) & -5.69045 & 0.0 \\\\ \\\\ \n",
      "\\textbf{St. Angelo} & -0.01646 & (0.00927) & -1.77462 & 0.07604 \\\\ \\\\ \n",
      "\\textbf{Austin} & -0.01705 & (0.01631) & -1.04584 & 0.2957 \\\\ \\\\ \n",
      "\\textbf{San Antonio} & 0.00479 & (0.00474) & 1.00937 & 0.31286 \\\\ \\\\ \n",
      "\\hline \\\\ \n",
      "\\end{tabular} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "est2 = estimate(reg1['LWW'],sm.add_constant(reg1[covariates]),2)\n",
    "write_table('results/prelim_results.tex', est2, labels=(nice_ww, nice_cov))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7.690497444933137, 7.629614031792577, 1.8612577223820765e-14, 2.9688370983063555e-14)\n"
     ]
    }
   ],
   "source": [
    "test1 = estimate(Y, sm.add_constant(X), 2)\n",
    "test2 = estimate(Y, sm.add_constant(X), 1)\n",
    "\n",
    "def nonnested_test(model1,model2):\n",
    "    \"\"\"test for non nested models quang vuong\"\"\"\n",
    "    \n",
    "    params1, se1, r21, y1, x1, ncomp1, ll1 = model1\n",
    "    params2, se2, r22, y2, x2, ncomp2, ll2 = model2\n",
    "    nobs, k = x1.shape\n",
    "    \n",
    "    k1 = params1.shape[1]*ncomp1 - 1 \n",
    "    k2 = params2.shape[1]*ncomp2 - 1\n",
    "    \n",
    "    var1 = (ll1 -ll2).std()\n",
    "    test1 = (ll1.sum() - ll2.sum() - k1 + k2)*nobs**(-.5)\n",
    "    test1 = test1/var1\n",
    "    p1 = 1 - stats.t.cdf(np.abs(test1),df=(nobs-k1-k2)) + stats.t.cdf(-np.abs(test1),df=(nobs-k1-k2))\n",
    "    \n",
    "    var2 =  ((ll1 - ll2)**2).mean()**.5\n",
    "    test2 = (ll1.sum() - ll2.sum() - k1 + k2 )*nobs**(-.5)\n",
    "    test2 = test2/var2\n",
    "    p2 = 1 - stats.t.cdf(np.abs(test2),df=(nobs-k1-k2)) + stats.t.cdf(-np.abs(test2),df=(nobs-k1-k2))\n",
    "    \n",
    "    return test1, test2, p1, p2\n",
    "\n",
    "print nonnested_test(est2,est1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_nonnested(model1,model2,fname):\n",
    "    test1, test2, p1, p2 = nonnested_test(model1,model2)\n",
    "    test1, test2, p1, p2 = np.round(test1,5), np.round(test2,5), np.round(p1,5), np.round(p2,5) \n",
    "    f = open(fname, \"w+\")\n",
    "    f.write('\\\\begin{tabular}{lcc}')\n",
    "    f.write('\\n\\\\hline \\n & \\\\textbf{t} & \\\\textbf{P $>$ $|$ t $|$} \\\\\\\\')\n",
    "    f.write('\\n\\\\hline')\n",
    "    f.write('\\n\\\\textbf{Test 1} & %s & %s \\\\\\\\'%(test1,p1))\n",
    "    f.write('\\n\\\\textbf{Test 2} & %s & %s \\\\\\\\'%(test2,p2))\n",
    "    f.write('\\\\hline \\\\\\\\ \\n')   \n",
    "    f.write('\\n\\\\end{tabular}\\n')\n",
    "    f.close()\n",
    "\n",
    "write_nonnested(est2,est1,'results/test_stat.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
