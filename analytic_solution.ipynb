{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.base.model import GenericLikelihoodModel\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "beta01, beta11 = 5,-3\n",
    "beta02, beta12 = 2, 4\n",
    "\n",
    "#set up regression mixture\n",
    "x1 = np.random.uniform(0, 10, size=400)\n",
    "x2 = np.random.uniform(0, 10, size=600)\n",
    "\n",
    "y1 = beta01 + beta11*x1 + np.random.normal(scale=5.0, size=400)\n",
    "y2 = beta02 + beta12*x2 + np.random.normal(scale=4.0,size=600)\n",
    "\n",
    "X = np.concatenate([x1, x2])\n",
    "Y = np.concatenate([y1, y2])\n",
    "\n",
    "\n",
    "#set up 2 component mixture\n",
    "a1 = np.random.normal(2, 5, size=600)\n",
    "a2 = np.random.normal(5, 3, size=400)\n",
    "a = np.concatenate([a1,a2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 2])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1,2])[[1,0,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.41923911  5.27416605 -3.0554598   3.09273167]\n",
      " [ 0.58076089  2.98164905  3.88695089  2.90872784]]\n",
      "----\n",
      "[[0.13593678 0.08117191 0.00246764]\n",
      " [0.13593678 0.05639045 0.00175354]]\n"
     ]
    }
   ],
   "source": [
    "def e_step(y,x,params): \n",
    "    nobs, k = x.shape\n",
    "    weights = []\n",
    "    for param in params:\n",
    "        sigma = param[-1]\n",
    "        beta = np.tile(param[1:-1],nobs).reshape(nobs, k)\n",
    "        mean = (beta*x).sum(axis=1)\n",
    "        weights.append( stats.norm.pdf(y, loc=mean, scale=sigma) )\n",
    "\n",
    "    #update loop variables\n",
    "    weights = np.array(weights).transpose()\n",
    "    denom = np.repeat(weights.sum(axis= 1),len(params)).reshape(nobs,len(params))\n",
    "    weights = (weights/denom)\n",
    "    return weights\n",
    "        \n",
    "    \n",
    "def m_step(y,x,weights):\n",
    "    nobs, k = x.shape\n",
    "    params, se, err = [], [], 0\n",
    "    \n",
    "    #do lambda estimates first becaues of order\n",
    "    lambs = weights.mean(axis=0)\n",
    "    lamb_ses = (np.sort(weights)).std(axis=0)\n",
    "    comp_order = stats.rankdata(weights.mean(axis=0),method='ordinal')\n",
    "    lamb_ses = lamb_ses[comp_order-1]\n",
    "    \n",
    "    \n",
    "    for i in comp_order:\n",
    "        try:\n",
    "            #component estimates\n",
    "            w = weights[:,i-1]\n",
    "            lamb = lambs[i-1]\n",
    "            lamb_se = lamb_ses[i-1]\n",
    "\n",
    "            #beta\n",
    "            w_mat = np.diag(w)\n",
    "            xx_mat = np.linalg.inv( x.transpose().dot( w_mat).dot(x) )\n",
    "            beta = xx_mat.dot(x.transpose().dot(w_mat)).dot(y)\n",
    "\n",
    "            #sigma\n",
    "            mu = np.tile(beta, nobs).reshape(nobs, k)*x\n",
    "            weighted_err = w*(y - mu.sum(axis=1))\n",
    "            sigma =  weighted_err.std()\n",
    "\n",
    "            #add component\n",
    "            comp_param =np.concatenate(([lamb],beta,[sigma]))\n",
    "            params.append(comp_param)\n",
    "\n",
    "            #beta_se\n",
    "            beta_se = np.diagonal(xx_mat*sigma**2)\n",
    "            comp_se = np.concatenate(([lamb_se],beta_se))\n",
    "            se.append(comp_se)\n",
    "\n",
    "            #SSR\n",
    "            err = err+weighted_err    \n",
    "            \n",
    "        except:        \n",
    "            params.append(np.concatenate( (np.zeros(k+1),[1]) ))\n",
    "            se.append( np.zeros(k+1) )\n",
    "    \n",
    "    return np.array(params), np.array(se), 1-err.var()/y.var()\n",
    "\n",
    "\n",
    "def gen_weights(nobs,ncomp):\n",
    "    weights = np.random.uniform(size=(nobs,ncomp))\n",
    "    denom = np.repeat(weights.sum(axis= 1),ncomp).reshape(nobs,ncomp)\n",
    "    return (weights/denom)\n",
    "\n",
    "\n",
    "def estimate(y,x,ncomp):\n",
    "    e = gen_weights(len(x),ncomp)\n",
    "    m = None\n",
    "    for i in range(15):\n",
    "        m,se,r2 = m_step(y,x,e)\n",
    "        e = e_step(y,x,m)\n",
    "    return m, se, r2, y, x, ncomp\n",
    "\n",
    "ests  = estimate(Y,sm.add_constant(X),2)\n",
    "m, se, r2, y, x, ncomp = estimate(Y,sm.add_constant(X),2)\n",
    "\n",
    "print m\n",
    "print '----'\n",
    "print se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.96667375e-01 -5.43102372e+00  1.42570827e+00  3.76729812e-02\n",
      "  -9.32507833e-02  1.36412006e-02]\n",
      " [ 7.03332625e-01 -2.22353754e+00  1.53568489e-01  3.16081267e-03\n",
      "   1.60746262e-02  8.75054154e-02]]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('data/milk.csv')\n",
    "reg1 = data[['WW','FMO','INC','ESC','ESTQTY','DEL','COOLER','NUMSCHL']].dropna()\n",
    "reg1['QSTOP'] = reg1['ESTQTY']/(reg1['DEL']*reg1['NUMSCHL'])\n",
    "reg1 = sm.add_constant(reg1)\n",
    "reg1[['WW','FMO','QSTOP','DEL']] = np.log(reg1[['WW','FMO','QSTOP','DEL']])\n",
    "\n",
    "est = estimate(np.array(reg1['WW']),np.array(reg1[['const','FMO','INC','DEL']]),2)\n",
    "print est[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_table(fname, estimates, labels=('y',None)):\n",
    "    \n",
    "    #unpack relevant information\n",
    "    params, se, r2, y, x, ncomp = estimates\n",
    "    nobs, k = x.shape\n",
    "    ylabel, xlabel = labels\n",
    "    \n",
    "    if xlabel == None:\n",
    "        xlabel =[]\n",
    "        for i in range(k):\n",
    "            xlabel.append('x%s'%i)\n",
    "            \n",
    "    assert (k == len(xlabel)) \n",
    "    \n",
    "    f = open(fname, \"w+\")\n",
    "    \n",
    "    f.write(('\\\\begin{center}  \\n'+\n",
    "            '\\\\begin{tabular}{lclc} \\n'+\n",
    "            '\\\\toprule \\n'+\n",
    "            '\\\\textbf{Dep. Variable:} & %s & \\\\textbf{  R-squared: } &  %s \\\\\\\\ \\n'%(ylabel, np.round(r2,3))  ))\n",
    "    \n",
    "    f.write(('\\\\textbf{No. Observations:} & %s & & \\\\\\\\ \\n'%nobs+\n",
    "            '\\end{tabular} \\n'))\n",
    "    \n",
    "    \n",
    "    f.write('\\n\\\\begin{tabular}{lcccc} \\n')\n",
    "    for comp in range(ncomp):\n",
    "        f.write('\\\\toprule \\n')\n",
    "        f.write('\\\\textbf{Regime %s} & \\\\textbf{est} & \\\\textbf{std err} &'%(1+comp)+ \n",
    "                '\\\\textbf{t} & \\\\textbf{P $>$ $|$ t $|$} \\\\\\\\ \\n')\n",
    "        f.write('\\\\bottomrule \\\\\\\\ \\n')\n",
    "        #isolate parasm\n",
    "        comp_params = params[comp]\n",
    "        comp_se = se[comp]\n",
    "        comp_t = np.abs(comp_params[:-1]/comp_se)\n",
    "        comp_p = 1 - stats.t.cdf(comp_t,df=nobs)\n",
    "        \n",
    "        #round everything\n",
    "        comp_params = np.round(comp_params,5)\n",
    "        comp_se = np.round(comp_se,5)\n",
    "        comp_t = np.round(comp_t,5)\n",
    "        comp_p = np.round(comp_p,5)\n",
    "        \n",
    "        lamb, lamb_se, lamb_t, lamb_p = comp_params[0], comp_se[0], comp_t[0], comp_p[0]\n",
    "        beta, beta_se, beta_t, beta_p = comp_params[1:-1], comp_se[1:], comp_t[1:], comp_p[1:]\n",
    "        sigma = comp_params[-1]\n",
    "        \n",
    "        \n",
    "        f.write('\\\\textbf{lambda} & %s & (%s) & %s & %s \\\\\\\\ \\\\\\\\ \\n'%(lamb,lamb_se,lamb_t,lamb_p) )\n",
    "        \n",
    "        for i in range(k):\n",
    "            f.write('\\\\textbf{%s} & %s & (%s) & %s & %s \\\\\\\\ \\\\\\\\ \\n'%(xlabel[i],beta[i],beta_se[i],\n",
    "                                                                             beta_t[i],beta_p[i]) )\n",
    "        \n",
    "        f.write('\\\\textbf{sigma} & %s &  & & \\\\\\\\ \\\\\\\\ \\n'%(sigma) )\n",
    "    \n",
    "    f.write('\\end{tabular} \\n'+\n",
    "            '\\end{center}\\n')\n",
    "\n",
    "write_table('out1.tex', ests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_table('prelim_results.tex', est, labels=('WW',['const','FMO','INC','COOLER']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
