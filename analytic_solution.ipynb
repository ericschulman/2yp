{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.base.model import GenericLikelihoodModel\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from scipy import cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "beta01, beta11 = 5,-3\n",
    "beta02, beta12 = 2, 4\n",
    "\n",
    "#set up regression mixture\n",
    "x1 = np.random.uniform(0, 10, size=400)\n",
    "x2 = np.random.uniform(0, 10, size=600)\n",
    "\n",
    "y1 = beta01 + beta11*x1 + np.random.normal(scale=5.0, size=400)\n",
    "y2 = beta02 + beta12*x2 + np.random.normal(scale=4.0,size=600)\n",
    "\n",
    "X = np.concatenate([x1, x2])\n",
    "Y = np.concatenate([y1, y2])\n",
    "\n",
    "\n",
    "#set up 2 component mixture\n",
    "a1 = np.random.normal(2, 5, size=600)\n",
    "a2 = np.random.normal(5, 3, size=400)\n",
    "a = np.concatenate([a1,a2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def e_step(y,x,params): \n",
    "    y, x = np.array(y), np.array(x)\n",
    "    nobs, k = x.shape\n",
    "    weights = []\n",
    "    for param in params:\n",
    "\n",
    "        sigma = param[-1]\n",
    "        beta = np.tile(param[1:-1],nobs).reshape(nobs, k)\n",
    "        mean = (beta*x).sum(axis=1)\n",
    "        weights.append( stats.norm.pdf(y, loc=mean, scale=sigma)*param[0] )\n",
    "        \n",
    "    #update loop variables\n",
    "    weights = np.array(weights).transpose()\n",
    "    #denom = np.repeat( 1+np.exp(weights).sum(axis=1), len(params) ).reshape(nobs,len(params))\n",
    "    denom = np.repeat(weights.sum(axis=1), len(params) ).reshape(nobs,len(params))\n",
    "    weights = weights/denom\n",
    "    return weights, np.log(denom[:,0])\n",
    "        \n",
    "    \n",
    "def m_step(y,x,weights):\n",
    "    y, x, weights = np.array(y), np.array(x), np.array(weights)\n",
    "    nobs, k = x.shape\n",
    "    params, se, err = [], [], 0\n",
    "\n",
    "    for w in weights.transpose():\n",
    "        \n",
    "        lamb = w.mean()\n",
    "        lamb_se = w.std()\n",
    "\n",
    "        #beta\n",
    "        w_mat = np.diag(w)\n",
    "        xx_mat = np.linalg.inv( x.transpose().dot( w_mat).dot(x) )\n",
    "        beta = xx_mat.dot(x.transpose().dot(w_mat)).dot(y)\n",
    "        \n",
    "        #sigma\n",
    "        mu = np.tile(beta, nobs).reshape(nobs, k)*x\n",
    "        weighted_err = w*(y - mu.sum(axis=1))**2\n",
    "        sigma =  (weighted_err.sum()/w.sum())**.5\n",
    "\n",
    "        #add component\n",
    "        comp_param =np.concatenate(([lamb],beta,[sigma]))\n",
    "        params.append(comp_param)\n",
    "\n",
    "        #beta_se\n",
    "        beta_se = (np.diagonal(xx_mat*sigma**2))**.5\n",
    "        comp_se = np.concatenate(([lamb_se],beta_se))\n",
    "        se.append(comp_se)\n",
    "\n",
    "        #SSR\n",
    "        err = err+weighted_err\n",
    "    return np.array(params), np.array(se), 1-err.mean()/y.var()\n",
    "\n",
    "\n",
    "def gen_weights(y,ncomp):\n",
    "    c,labels = cluster.vq.kmeans2(y,ncomp)\n",
    "    return np.array(pd.get_dummies(labels))\n",
    "\n",
    "\n",
    "def estimate(y,x,ncomp):\n",
    "    e = gen_weights(y,ncomp)\n",
    "    m = None\n",
    "    for i in range(20):\n",
    "        m,se,r2 = m_step(y,x,e)\n",
    "        e,ll = e_step(y,x,m)\n",
    "    return m, se, r2, y, x, ncomp, e, ll\n",
    "\n",
    "\n",
    "m, se, r2, y, x, ncomp, classes, ll = estimate(Y, sm.add_constant(X), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_table(fname, estimates, labels=('y',None)):\n",
    "    \n",
    "    #unpack relevant information\n",
    "    params, se, r2, y, x, ncomp, ll, classes = estimates\n",
    "    nobs, k = x.shape\n",
    "    ylabel, xlabel = labels\n",
    "    \n",
    "    #calc aic\n",
    "    aic = 2*(params.shape[0]*params.shape[1]-2) - 2*ll.sum()\n",
    "    aic = np.round(aic,1)\n",
    "    \n",
    "    if xlabel == None:\n",
    "        xlabel =[]\n",
    "        for i in range(k):\n",
    "            xlabel.append('x%s'%i)\n",
    "            \n",
    "    assert (k == len(xlabel)) \n",
    "    \n",
    "    f = open(fname, \"w+\")\n",
    "    \n",
    "    f.write(('\\\\small \\n'+\n",
    "            '\\\\begin{tabular}{lclc} \\n'+\n",
    "            '\\\\hline \\n'+\n",
    "            '\\\\textbf{Dep. Variable:} & %s & \\\\textbf{  R-squared: } &  %s \\\\\\\\ \\n'%(ylabel, np.round(r2,3))  ))\n",
    "    \n",
    "    f.write(('\\\\textbf{No. Observations:} & %s & \\\\textbf{ AIC:} & %s \\\\\\\\ \\n'%(nobs,aic)+\n",
    "                                                                                    \n",
    "            '\\end{tabular} \\n'))\n",
    "    \n",
    "    \n",
    "    f.write('\\n\\\\begin{tabular}{lcccc} \\n')\n",
    "    for comp in range(ncomp):\n",
    "        f.write('\\\\hline \\n')\n",
    "        f.write('\\\\textbf{Phase %s} & \\\\textbf{Estimate} & \\\\textbf{Std. Error} &'%(1+comp)+ \n",
    "                '\\\\textbf{t} & \\\\textbf{P $>$ $|$ t $|$} \\\\\\\\ \\n')\n",
    "        f.write('\\\\hline \\\\\\\\ \\n')\n",
    "        \n",
    "        #isolate params\n",
    "        comp_params = params[comp]\n",
    "        comp_se = se[comp]\n",
    "        comp_t = comp_params[:-1]/comp_se\n",
    "        comp_p = 1 - stats.t.cdf(np.abs(comp_t),df=(nobs-k)) + stats.t.cdf(-np.abs(comp_t),df=(nobs-k))\n",
    "        \n",
    "        #round everything\n",
    "        comp_params = np.round(comp_params,5)\n",
    "        comp_se = np.round(comp_se,5)\n",
    "        comp_t = np.round(comp_t,5)\n",
    "        comp_p = np.round(comp_p,5)\n",
    "        \n",
    "        lamb, lamb_se = comp_params[0], comp_se[0]\n",
    "        #lamb_t, lamb_p = comp_params[0],  comp_t[0], comp_p[0]\n",
    "        beta, beta_se, beta_t, beta_p = comp_params[1:-1], comp_se[1:], comp_t[1:], comp_p[1:]\n",
    "        sigma = comp_params[-1]\n",
    "        \n",
    "        if ncomp > 1:\n",
    "            f.write('\\\\textbf{Pr(phase %s)} & %s  & %s & & \\\\\\\\ \\\\\\\\ \\n'%(comp+1, lamb, lamb_se) )\n",
    "        \n",
    "        for i in range(k):\n",
    "            f.write('\\\\textbf{%s} & %s & (%s) & %s & %s \\\\\\\\ \\\\\\\\ \\n'%(xlabel[i],beta[i],beta_se[i],\n",
    "                                                                             beta_t[i],beta_p[i]) )\n",
    "        \n",
    "        #f.write('\\\\textbf{Variance} & %s &  & & \\\\\\\\ \\\\\\\\ \\n'%(sigma) )\n",
    "    f.write('\\\\hline \\\\\\\\ \\n')    \n",
    "    f.write('\\end{tabular} \\n')\n",
    "    f.close()\n",
    "    \n",
    "    #print output\n",
    "    f = open(fname, \"r\")\n",
    "    print(f.read())\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'YEAR', 'MONTH', 'DAY', 'SYSTEM', 'FMOZONE', 'VENDOR',\n",
      "       'COUNTY', 'LSCORE', 'LFMO', 'LGAS', 'LPOPUL', 'LQSCORE', 'COOLER',\n",
      "       'ESC', 'ONEBID', 'NUM', '3', '6', '7', '9', 'INC', 'LSCORE_min1',\n",
      "       'LSCORE_min2', 'LSCORE_min3', 'LSCORE_min4', 'LSCORE_min5',\n",
      "       'LSCORE_max1', 'LSCORE_max2', 'LSCORE_max3', 'LSCORE_max4',\n",
      "       'LSCORE_max5', 'WIN'],\n",
      "      dtype='object')\n",
      "['LFMO', 'LGAS', 'LPOPUL', 'LQSCORE', 'COOLER', 'ESC', 'ONEBID', 'NUM', '3', '6', '7', '9']\n",
      "['INC', 'LSCORE_min1', 'LSCORE_min2', 'LSCORE_min3', 'LSCORE_min4', 'LSCORE_min5', 'LSCORE_max1', 'LSCORE_max2', 'LSCORE_max3', 'LSCORE_max4', 'LSCORE_max5']\n"
     ]
    }
   ],
   "source": [
    "reg1 = pd.read_csv('data/clean_milk1.csv')\n",
    "print(reg1.columns)\n",
    "\n",
    "#variables names\n",
    "lmilk = ['LSCORE']\n",
    "auct_key = ['YEAR','MONTH','DAY','SYSTEM','FMOZONE']\n",
    "lcts = ['LFMO','LGAS','LPOPUL','LQSCORE']#,'LMEALS']\n",
    "dummies = ['COOLER','ESC', 'ONEBID','NUM']\n",
    "\n",
    "fekeys = list(reg1.columns[17:-12])\n",
    "\n",
    "\n",
    "lags = 5\n",
    "lagkeys = [l+str(i) for l in ['LSCORE_min','LSCORE_max'] for i in range(1,1+lags)]\n",
    "\n",
    "bid_key = auct_key + ['VENDOR'] + ['COUNTY']\n",
    "covariates = lcts + dummies + fekeys\n",
    "hist = ['INC'] + lagkeys\n",
    "\n",
    "print(covariates)\n",
    "print(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nice_ww = 'Bids (log-log)'\n",
    "nice_cov = ['(Intercept)', 'Raw milk', 'Gas',\n",
    "            'Population', 'Quantity', #'Meals',\n",
    "            'Cooler', 'Escalated', 'Monopoly' ,'No. Bidders', #+ fekeys\n",
    "            'Waco','St. Angelo', 'Austin', 'San Antonio']\n",
    "nice_lags = [l+str(i) for l in ['Min. lag \\#','Max. lag \\#'] for i in range(1,1+lags)]\n",
    "nice_lags = ['Incumbency'] + nice_lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erichschulman/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\small \n",
      "\\begin{tabular}{lclc} \n",
      "\\hline \n",
      "\\textbf{Dep. Variable:} & Bids (log-log) & \\textbf{  R-squared: } &  0.166 \\\\ \n",
      "\\textbf{No. Observations:} & 4040 & \\textbf{ AIC:} & -8054.0 \\\\ \n",
      "\\end{tabular} \n",
      "\n",
      "\\begin{tabular}{lcccc} \n",
      "\\hline \n",
      "\\textbf{Phase 1} & \\textbf{Estimate} & \\textbf{Std. Error} &\\textbf{t} & \\textbf{P $>$ $|$ t $|$} \\\\ \n",
      "\\hline \\\\ \n",
      "\\textbf{(Intercept)} & -2.28614 & (0.07704) & -29.67319 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Raw milk} & 0.21012 & (0.02823) & 7.44213 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Gas} & 0.02365 & (0.00425) & 5.56968 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Population} & 0.0151 & (0.00326) & 4.63236 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Quantity} & -0.01997 & (0.00342) & -5.83102 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Cooler} & 0.01851 & (0.0031) & 5.96343 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Escalated} & -0.0273 & (0.0029) & -9.41336 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Monopoly} & 0.01815 & (0.00583) & 3.11206 & 0.00187 \\\\ \\\\ \n",
      "\\textbf{No. Bidders} & 0.00775 & (0.00157) & 4.92298 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Waco} & -0.06971 & (0.00436) & -15.98917 & 0.0 \\\\ \\\\ \n",
      "\\textbf{St. Angelo} & -0.04618 & (0.0129) & -3.58115 & 0.00035 \\\\ \\\\ \n",
      "\\textbf{Austin} & -0.0896 & (0.01486) & -6.03043 & 0.0 \\\\ \\\\ \n",
      "\\textbf{San Antonio} & -0.05101 & (0.00415) & -12.29703 & 0.0 \\\\ \\\\ \n",
      "\\hline \\\\ \n",
      "\\end{tabular} \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erichschulman/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:41: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "est0 = estimate(reg1['LSCORE'],sm.add_constant(reg1[covariates]),1)\n",
    "write_table('results/ols_results.tex', est0, labels=(nice_ww, nice_cov))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\small \n",
      "\\begin{tabular}{lclc} \n",
      "\\hline \n",
      "\\textbf{Dep. Variable:} & Bids (log-log) & \\textbf{  R-squared: } &  0.208 \\\\ \n",
      "\\textbf{No. Observations:} & 4040 & \\textbf{ AIC:} & -8032.0 \\\\ \n",
      "\\end{tabular} \n",
      "\n",
      "\\begin{tabular}{lcccc} \n",
      "\\hline \n",
      "\\textbf{Phase 1} & \\textbf{Estimate} & \\textbf{Std. Error} &\\textbf{t} & \\textbf{P $>$ $|$ t $|$} \\\\ \n",
      "\\hline \\\\ \n",
      "\\textbf{(Intercept)} & -1.34236 & (0.10976) & -12.23018 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Raw milk} & 0.12469 & (0.02839) & 4.39156 & 1e-05 \\\\ \\\\ \n",
      "\\textbf{Gas} & 0.02207 & (0.00421) & 5.24695 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Population} & 0.00907 & (0.00322) & 2.81635 & 0.00488 \\\\ \\\\ \n",
      "\\textbf{Quantity} & -0.01602 & (0.00337) & -4.74925 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Cooler} & 0.01741 & (0.00303) & 5.74009 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Escalated} & -0.0257 & (0.00283) & -9.06904 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Monopoly} & 0.00806 & (0.00628) & 1.28404 & 0.1992 \\\\ \\\\ \n",
      "\\textbf{No. Bidders} & 0.00655 & (0.00154) & 4.24428 & 2e-05 \\\\ \\\\ \n",
      "\\textbf{Waco} & -0.07273 & (0.00426) & -17.07025 & 0.0 \\\\ \\\\ \n",
      "\\textbf{St. Angelo} & -0.04851 & (0.01265) & -3.83489 & 0.00013 \\\\ \\\\ \n",
      "\\textbf{Austin} & -0.09508 & (0.01456) & -6.52829 & 0.0 \\\\ \\\\ \n",
      "\\textbf{San Antonio} & -0.05571 & (0.00407) & -13.67942 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Incumbency} & 0.0245 & (0.00671) & 3.65064 & 0.00026 \\\\ \\\\ \n",
      "\\textbf{Min. lag \\#1} & -0.0514 & (0.01793) & -2.8662 & 0.00418 \\\\ \\\\ \n",
      "\\textbf{Min. lag \\#2} & 0.04234 & (0.01805) & 2.34592 & 0.01903 \\\\ \\\\ \n",
      "\\textbf{Min. lag \\#3} & 0.05257 & (0.01818) & 2.89183 & 0.00385 \\\\ \\\\ \n",
      "\\textbf{Min. lag \\#4} & -0.00643 & (0.01815) & -0.35422 & 0.72319 \\\\ \\\\ \n",
      "\\textbf{Min. lag \\#5} & 0.08925 & (0.01768) & 5.04863 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Max. lag \\#1} & 0.14603 & (0.0189) & 7.7265 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Max. lag \\#2} & 0.03141 & (0.01861) & 1.68791 & 0.09151 \\\\ \\\\ \n",
      "\\textbf{Max. lag \\#3} & 0.06813 & (0.01854) & 3.67479 & 0.00024 \\\\ \\\\ \n",
      "\\textbf{Max. lag \\#4} & 0.05155 & (0.01801) & 2.86217 & 0.00423 \\\\ \\\\ \n",
      "\\textbf{Max. lag \\#5} & -0.02241 & (0.01843) & -1.21594 & 0.22408 \\\\ \\\\ \n",
      "\\hline \\\\ \n",
      "\\end{tabular} \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erichschulman/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:41: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "est1 = estimate(reg1['LSCORE'],sm.add_constant(reg1[covariates + hist]),1)\n",
    "write_table('results/hist_results.tex', est1, labels=(nice_ww, nice_cov + nice_lags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\small \n",
      "\\begin{tabular}{lclc} \n",
      "\\hline \n",
      "\\textbf{Dep. Variable:} & Bids (log-log) & \\textbf{  R-squared: } &  0.222 \\\\ \n",
      "\\textbf{No. Observations:} & 4027 & \\textbf{ AIC:} & -7986.0 \\\\ \n",
      "\\end{tabular} \n",
      "\n",
      "\\begin{tabular}{lcccc} \n",
      "\\hline \n",
      "\\textbf{Phase 1} & \\textbf{Estimate} & \\textbf{Std. Error} &\\textbf{t} & \\textbf{P $>$ $|$ t $|$} \\\\ \n",
      "\\hline \\\\ \n",
      "\\textbf{(Intercept)} & -0.89207 & (0.12601) & -7.0796 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Raw milk} & 0.09123 & (0.02859) & 3.19087 & 0.00143 \\\\ \\\\ \n",
      "\\textbf{Gas} & 0.01823 & (0.00423) & 4.31004 & 2e-05 \\\\ \\\\ \n",
      "\\textbf{Population} & 0.00694 & (0.00321) & 2.16011 & 0.03082 \\\\ \\\\ \n",
      "\\textbf{Quantity} & -0.01471 & (0.00336) & -4.38298 & 1e-05 \\\\ \\\\ \n",
      "\\textbf{Cooler} & 0.01705 & (0.00302) & 5.64209 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Escalated} & -0.02499 & (0.00282) & -8.86033 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Monopoly} & 0.00771 & (0.00626) & 1.23144 & 0.21823 \\\\ \\\\ \n",
      "\\textbf{No. Bidders} & 0.00611 & (0.00154) & 3.95282 & 8e-05 \\\\ \\\\ \n",
      "\\textbf{Waco} & -0.07426 & (0.00424) & -17.50899 & 0.0 \\\\ \\\\ \n",
      "\\textbf{St. Angelo} & -0.04631 & (0.01267) & -3.65477 & 0.00026 \\\\ \\\\ \n",
      "\\textbf{Austin} & -0.10917 & (0.01532) & -7.12447 & 0.0 \\\\ \\\\ \n",
      "\\textbf{San Antonio} & -0.05676 & (0.00405) & -14.03134 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Incumbency} & 0.02407 & (0.00667) & 3.6103 & 0.00031 \\\\ \\\\ \n",
      "\\textbf{Min. lag \\#1} & -0.05556 & (0.01787) & -3.10983 & 0.00189 \\\\ \\\\ \n",
      "\\textbf{Min. lag \\#2} & 0.04259 & (0.01805) & 2.36015 & 0.01832 \\\\ \\\\ \n",
      "\\textbf{Min. lag \\#3} & 0.05395 & (0.01817) & 2.96987 & 0.003 \\\\ \\\\ \n",
      "\\textbf{Min. lag \\#4} & -0.00644 & (0.01814) & -0.35521 & 0.72245 \\\\ \\\\ \n",
      "\\textbf{Min. lag \\#5} & 0.08797 & (0.01775) & 4.95596 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Min. lag \\#6} & 0.01716 & (0.01778) & 0.96502 & 0.33459 \\\\ \\\\ \n",
      "\\textbf{Min. lag \\#7} & 0.03016 & (0.01803) & 1.67288 & 0.09443 \\\\ \\\\ \n",
      "\\textbf{Min. lag \\#8} & 0.05967 & (0.01809) & 3.29769 & 0.00098 \\\\ \\\\ \n",
      "\\textbf{Min. lag \\#9} & 0.0364 & (0.01807) & 2.01436 & 0.04404 \\\\ \\\\ \n",
      "\\textbf{Min. lag \\#10} & 0.00121 & (0.01762) & 0.06893 & 0.94505 \\\\ \\\\ \n",
      "\\textbf{Max. lag \\#1} & 0.13158 & (0.01894) & 6.94783 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Max. lag \\#2} & 0.02014 & (0.01871) & 1.07661 & 0.28172 \\\\ \\\\ \n",
      "\\textbf{Max. lag \\#3} & 0.05303 & (0.01857) & 2.85528 & 0.00432 \\\\ \\\\ \n",
      "\\textbf{Max. lag \\#4} & 0.03976 & (0.01817) & 2.18815 & 0.02872 \\\\ \\\\ \n",
      "\\textbf{Max. lag \\#5} & -0.03743 & (0.01878) & -1.99286 & 0.04634 \\\\ \\\\ \n",
      "\\textbf{Max. lag \\#6} & 0.01712 & (0.01878) & 0.91147 & 0.3621 \\\\ \\\\ \n",
      "\\textbf{Max. lag \\#7} & 0.03884 & (0.01866) & 2.08141 & 0.03746 \\\\ \\\\ \n",
      "\\textbf{Max. lag \\#8} & 0.03052 & (0.01836) & 1.66266 & 0.09646 \\\\ \\\\ \n",
      "\\textbf{Max. lag \\#9} & 0.01918 & (0.01814) & 1.05753 & 0.29033 \\\\ \\\\ \n",
      "\\textbf{Max. lag \\#10} & 0.01415 & (0.01801) & 0.78564 & 0.43212 \\\\ \\\\ \n",
      "\\hline \\\\ \n",
      "\\end{tabular} \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erichschulman/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:41: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "lags2 = 10\n",
    "lagkeys2 = [l+str(i) for l in ['LSCORE_min','LSCORE_max'] for i in range(1,1+lags2)]\n",
    "nice_lags2 = [l+str(i) for l in ['Min. lag \\#','Max. lag \\#'] for i in range(1,1+lags2)]\n",
    "nice_lags2 = ['Incumbency'] + nice_lags2\n",
    "hist2 = ['INC'] + lagkeys2\n",
    "\n",
    "reg2 = pd.read_csv('data/clean_milk2.csv')\n",
    "est4 = estimate(reg2['LSCORE'],sm.add_constant(reg2[covariates + hist2]),1)\n",
    "write_table('results/hist_results2.tex', est4, labels=(nice_ww, nice_cov + nice_lags2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\small \n",
      "\\begin{tabular}{lclc} \n",
      "\\hline \n",
      "\\textbf{Dep. Variable:} & Bids (log-log) & \\textbf{  R-squared: } &  0.436 \\\\ \n",
      "\\textbf{No. Observations:} & 4040 & \\textbf{ AIC:} & -8024.0 \\\\ \n",
      "\\end{tabular} \n",
      "\n",
      "\\begin{tabular}{lcccc} \n",
      "\\hline \n",
      "\\textbf{Phase 1} & \\textbf{Estimate} & \\textbf{Std. Error} &\\textbf{t} & \\textbf{P $>$ $|$ t $|$} \\\\ \n",
      "\\hline \\\\ \n",
      "\\textbf{Pr(phase 1)} & 0.30682  & 0.24155 & & \\\\ \\\\ \n",
      "\\textbf{(Intercept)} & -2.77158 & (0.07732) & -35.84615 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Raw milk} & 0.40316 & (0.02803) & 14.38359 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Gas} & 0.016 & (0.00452) & 3.53681 & 0.00041 \\\\ \\\\ \n",
      "\\textbf{Population} & -0.00458 & (0.00303) & -1.50882 & 0.13142 \\\\ \\\\ \n",
      "\\textbf{Quantity} & -0.00951 & (0.00319) & -2.98142 & 0.00289 \\\\ \\\\ \n",
      "\\textbf{Cooler} & 0.01683 & (0.00318) & 5.29592 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Escalated} & -0.01158 & (0.00289) & -4.01229 & 6e-05 \\\\ \\\\ \n",
      "\\textbf{Monopoly} & 0.01148 & (0.00599) & 1.91799 & 0.05518 \\\\ \\\\ \n",
      "\\textbf{No. Bidders} & 0.01316 & (0.00159) & 8.2834 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Waco} & -0.1777 & (0.00463) & -38.35515 & 0.0 \\\\ \\\\ \n",
      "\\textbf{St. Angelo} & -0.08112 & (0.01366) & -5.93935 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Austin} & -0.24322 & (0.01414) & -17.20271 & 0.0 \\\\ \\\\ \n",
      "\\textbf{San Antonio} & -0.20242 & (0.00433) & -46.70512 & 0.0 \\\\ \\\\ \n",
      "\\hline \n",
      "\\textbf{Phase 2} & \\textbf{Estimate} & \\textbf{Std. Error} &\\textbf{t} & \\textbf{P $>$ $|$ t $|$} \\\\ \n",
      "\\hline \\\\ \n",
      "\\textbf{Pr(phase 2)} & 0.69318  & 0.24155 & & \\\\ \\\\ \n",
      "\\textbf{(Intercept)} & -2.14935 & (0.08499) & -25.29037 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Raw milk} & 0.17248 & (0.03132) & 5.50762 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Gas} & 0.0028 & (0.00461) & 0.60767 & 0.54344 \\\\ \\\\ \n",
      "\\textbf{Population} & 0.0255 & (0.00374) & 6.82518 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Quantity} & -0.02358 & (0.00392) & -6.01769 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Cooler} & 0.01493 & (0.00339) & 4.40487 & 1e-05 \\\\ \\\\ \n",
      "\\textbf{Escalated} & -0.02237 & (0.00323) & -6.93264 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Monopoly} & 0.01588 & (0.00637) & 2.49339 & 0.01269 \\\\ \\\\ \n",
      "\\textbf{No. Bidders} & 0.00246 & (0.00174) & 1.41964 & 0.15579 \\\\ \\\\ \n",
      "\\textbf{Waco} & -0.0286 & (0.0047) & -6.07944 & 0.0 \\\\ \\\\ \n",
      "\\textbf{St. Angelo} & -0.03539 & (0.01388) & -2.54956 & 0.01082 \\\\ \\\\ \n",
      "\\textbf{Austin} & -0.00602 & (0.01677) & -0.35918 & 0.71948 \\\\ \\\\ \n",
      "\\textbf{San Antonio} & 0.01033 & (0.00455) & 2.2686 & 0.02335 \\\\ \\\\ \n",
      "\\hline \\\\ \n",
      "\\end{tabular} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "est2 = estimate(reg1['LSCORE'],sm.add_constant(reg1[covariates]),2)\n",
    "write_table('results/prelim_results.tex', est2, labels=(nice_ww, nice_cov))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\small \n",
      "\\begin{tabular}{lclc} \n",
      "\\hline \n",
      "\\textbf{Dep. Variable:} & Punishment & \\textbf{  R-squared: } &  0.015 \\\\ \n",
      "\\textbf{No. Observations:} & 4040 & \\textbf{ AIC:} & -8058.0 \\\\ \n",
      "\\end{tabular} \n",
      "\n",
      "\\begin{tabular}{lcccc} \n",
      "\\hline \n",
      "\\textbf{Phase 1} & \\textbf{Estimate} & \\textbf{Std. Error} &\\textbf{t} & \\textbf{P $>$ $|$ t $|$} \\\\ \n",
      "\\hline \\\\ \n",
      "\\textbf{(Intercept)} & -0.83762 & (0.20403) & -4.10529 & 4e-05 \\\\ \\\\ \n",
      "\\textbf{Min. lag \\#1} & 0.00267 & (0.06505) & 0.04104 & 0.96726 \\\\ \\\\ \n",
      "\\textbf{Min. lag \\#2} & -0.26284 & (0.06569) & -4.0013 & 6e-05 \\\\ \\\\ \n",
      "\\textbf{Min. lag \\#3} & -0.18554 & (0.0662) & -2.80259 & 0.00509 \\\\ \\\\ \n",
      "\\textbf{Min. lag \\#4} & -0.0121 & (0.06616) & -0.18283 & 0.85494 \\\\ \\\\ \n",
      "\\textbf{Min. lag \\#5} & -0.26809 & (0.06459) & -4.1507 & 3e-05 \\\\ \\\\ \n",
      "\\textbf{Max. lag \\#1} & -0.14741 & (0.06799) & -2.16823 & 0.0302 \\\\ \\\\ \n",
      "\\textbf{Max. lag \\#2} & 0.16855 & (0.06706) & 2.51351 & 0.01199 \\\\ \\\\ \n",
      "\\textbf{Max. lag \\#3} & -0.06614 & (0.06732) & -0.98259 & 0.32587 \\\\ \\\\ \n",
      "\\textbf{Max. lag \\#4} & 0.0971 & (0.06567) & 1.47854 & 0.13934 \\\\ \\\\ \n",
      "\\textbf{Max. lag \\#5} & 0.16374 & (0.06714) & 2.43873 & 0.01478 \\\\ \\\\ \n",
      "\\hline \\\\ \n",
      "\\end{tabular} \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erichschulman/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:41: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "punish = est2[-2].mean(axis=0).argmin()\n",
    "\n",
    "classes = reg1.copy()[['SYSTEM','FMOZONE','YEAR','MONTH','DAY']]\n",
    "\n",
    "classes['classes'] = 1.*(est2[-2][:,punish]>.5)\n",
    "classes['prob'] =  1.*(est2[-2][:,punish])\n",
    "classes['SCORE'] = np.exp(reg1['LSCORE'])\n",
    "classes.to_csv('data/classes.csv')\n",
    "\n",
    "est3 = estimate(classes['classes'],sm.add_constant(reg1[hist[1:]]),1)\n",
    "write_table('results/phase_res.tex', est3, labels=('Punishment', ['(Intercept)'] + nice_lags[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6.478109281955905, 6.443351593498305, 1.0418530351974065e-10, 1.3077738496458997e-10)\n"
     ]
    }
   ],
   "source": [
    "test1 = estimate(Y, sm.add_constant(X), 2)\n",
    "test2 = estimate(Y, sm.add_constant(X), 1)\n",
    "\n",
    "def nonnested_test(model1,model2):\n",
    "    \"\"\"test for non nested models quang vuong\"\"\"\n",
    "    \n",
    "    params1, se1, r21, y1, x1, ncomp1, classes1, ll1 = model1\n",
    "    params2, se2, r22, y2, x2, ncomp2, classes2, ll2 = model2\n",
    "    nobs, k = x1.shape\n",
    "    \n",
    "    k1 = params1.shape[1]*ncomp1 - 1 \n",
    "    k2 = params2.shape[1]*ncomp2 - 1\n",
    "    \n",
    "    var1 = (ll1 -ll2).std()\n",
    "    test1 = (ll1.sum() - ll2.sum() - k1 + k2)*nobs**(-.5)\n",
    "    test1 = test1/var1\n",
    "    p1 = 1 - stats.t.cdf(np.abs(test1),df=(nobs-k1-k2)) + stats.t.cdf(-np.abs(test1),df=(nobs-k1-k2))\n",
    "    \n",
    "    var2 =  ((ll1 - ll2)**2).mean()**.5\n",
    "    test2 = (ll1.sum() - ll2.sum() - k1 + k2 )*nobs**(-.5)\n",
    "    test2 = test2/var2\n",
    "    p2 = 1 - stats.t.cdf(np.abs(test2),df=(nobs-k1-k2)) + stats.t.cdf(-np.abs(test2),df=(nobs-k1-k2))\n",
    "    \n",
    "    return test1, test2, p1, p2\n",
    "\n",
    "print(nonnested_test(est2,est1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_nonnested(model1,model2,fname):\n",
    "    test1, test2, p1, p2 = nonnested_test(model1,model2)\n",
    "    test1, test2, p1, p2 = np.round(test1,5), np.round(test2,5), np.round(p1,5), np.round(p2,5) \n",
    "    f = open(fname, \"w+\")\n",
    "    f.write('\\\\begin{tabular}{lcc}')\n",
    "    f.write('\\n\\\\hline \\n & \\\\textbf{t} & \\\\textbf{P $>$ $|$ t $|$} \\\\\\\\')\n",
    "    f.write('\\n\\\\hline')\n",
    "    f.write('\\n\\\\textbf{Test 1} & %s & %s \\\\\\\\'%(test1,p1))\n",
    "    f.write('\\n\\\\textbf{Test 2} & %s & %s \\\\\\\\'%(test2,p2))\n",
    "    f.write('\\\\hline \\\\\\\\ \\n')   \n",
    "    f.write('\\n\\\\end{tabular}\\n')\n",
    "    f.close()\n",
    "\n",
    "write_nonnested(est2,est1,'results/test_stat.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
