{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.base.model import GenericLikelihoodModel\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from scipy import cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "beta01, beta11 = 5,-3\n",
    "beta02, beta12 = 2, 4\n",
    "\n",
    "#set up regression mixture\n",
    "x1 = np.random.uniform(0, 10, size=400)\n",
    "x2 = np.random.uniform(0, 10, size=600)\n",
    "\n",
    "y1 = beta01 + beta11*x1 + np.random.normal(scale=5.0, size=400)\n",
    "y2 = beta02 + beta12*x2 + np.random.normal(scale=4.0,size=600)\n",
    "\n",
    "X = np.concatenate([x1, x2])\n",
    "Y = np.concatenate([y1, y2])\n",
    "\n",
    "\n",
    "#set up 2 component mixture\n",
    "a1 = np.random.normal(2, 5, size=600)\n",
    "a2 = np.random.normal(5, 3, size=400)\n",
    "a = np.concatenate([a1,a2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def e_step(y,x,params): \n",
    "    y, x = np.array(y), np.array(x)\n",
    "    nobs, k = x.shape\n",
    "    weights = []\n",
    "    for param in params:\n",
    "\n",
    "        sigma = param[-1]\n",
    "        beta = np.tile(param[1:-1],nobs).reshape(nobs, k)\n",
    "        mean = (beta*x).sum(axis=1)\n",
    "        weights.append( stats.norm.pdf(y, loc=mean, scale=sigma)*param[0] )\n",
    "        \n",
    "    #update loop variables\n",
    "    weights = np.array(weights).transpose()\n",
    "    #denom = np.repeat( 1+np.exp(weights).sum(axis=1), len(params) ).reshape(nobs,len(params))\n",
    "    denom = np.repeat(weights.sum(axis=1), len(params) ).reshape(nobs,len(params))\n",
    "    weights = weights/denom\n",
    "    return weights, np.log(denom[:,0])\n",
    "        \n",
    "    \n",
    "def m_step(y,x,weights):\n",
    "    y, x, weights = np.array(y), np.array(x), np.array(weights)\n",
    "    nobs, k = x.shape\n",
    "    params, se, err = [], [], 0\n",
    "\n",
    "    for w in weights.transpose():\n",
    "        \n",
    "        lamb = w.mean()\n",
    "        lamb_se = w.std()\n",
    "\n",
    "        #beta\n",
    "        w_mat = np.diag(w)\n",
    "        xx_mat = np.linalg.inv( x.transpose().dot( w_mat).dot(x) )\n",
    "        beta = xx_mat.dot(x.transpose().dot(w_mat)).dot(y)\n",
    "        \n",
    "        #sigma\n",
    "        mu = np.tile(beta, nobs).reshape(nobs, k)*x\n",
    "        weighted_err = w*(y - mu.sum(axis=1))**2\n",
    "        sigma =  (weighted_err.sum()/w.sum())**.5\n",
    "\n",
    "        #add component\n",
    "        comp_param =np.concatenate(([lamb],beta,[sigma]))\n",
    "        params.append(comp_param)\n",
    "\n",
    "        #beta_se\n",
    "        beta_se = (np.diagonal(xx_mat*sigma**2))**.5\n",
    "        comp_se = np.concatenate(([lamb_se],beta_se))\n",
    "        se.append(comp_se)\n",
    "\n",
    "        #SSR\n",
    "        err = err+weighted_err\n",
    "    return np.array(params), np.array(se), 1-err.mean()/y.var()\n",
    "\n",
    "\n",
    "def gen_weights(y,ncomp):\n",
    "    c,labels = cluster.vq.kmeans2(y,ncomp)\n",
    "    return np.array(pd.get_dummies(labels))\n",
    "\n",
    "\n",
    "def estimate(y,x,ncomp):\n",
    "    e = gen_weights(y,ncomp)\n",
    "    m = None\n",
    "    for i in range(20):\n",
    "        m,se,r2 = m_step(y,x,e)\n",
    "        e,ll = e_step(y,x,m)\n",
    "    return m, se, r2, y, x, ncomp, ll\n",
    "\n",
    "\n",
    "m, se, r2, y, x, ncomp, ll = estimate(Y, sm.add_constant(X), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_table(fname, estimates, labels=('y',None)):\n",
    "    \n",
    "    #unpack relevant information\n",
    "    params, se, r2, y, x, ncomp, ll = estimates\n",
    "    nobs, k = x.shape\n",
    "    ylabel, xlabel = labels\n",
    "    \n",
    "    #calc aic\n",
    "    aic = 2*(params.shape[0]*params.shape[1]-2) - 2*ll.sum()\n",
    "    aic = np.round(aic,1)\n",
    "    \n",
    "    if xlabel == None:\n",
    "        xlabel =[]\n",
    "        for i in range(k):\n",
    "            xlabel.append('x%s'%i)\n",
    "            \n",
    "    assert (k == len(xlabel)) \n",
    "    \n",
    "    f = open(fname, \"w+\")\n",
    "    \n",
    "    f.write(('\\\\small \\n'+\n",
    "            '\\\\begin{tabular}{lclc} \\n'+\n",
    "            '\\\\hline \\n'+\n",
    "            '\\\\textbf{Dep. Variable:} & %s & \\\\textbf{  R-squared: } &  %s \\\\\\\\ \\n'%(ylabel, np.round(r2,3))  ))\n",
    "    \n",
    "    f.write(('\\\\textbf{No. Observations:} & %s & \\\\textbf{ AIC:} & %s \\\\\\\\ \\n'%(nobs,aic)+\n",
    "                                                                                    \n",
    "            '\\end{tabular} \\n'))\n",
    "    \n",
    "    \n",
    "    f.write('\\n\\\\begin{tabular}{lcccc} \\n')\n",
    "    for comp in range(ncomp):\n",
    "        f.write('\\\\hline \\n')\n",
    "        f.write('\\\\textbf{Phase %s} & \\\\textbf{Est.} & \\\\textbf{Std. Err.} &'%(1+comp)+ \n",
    "                '\\\\textbf{t} & \\\\textbf{P $>$ $|$ t $|$} \\\\\\\\ \\n')\n",
    "        f.write('\\\\hline \\\\\\\\ \\n')\n",
    "        \n",
    "        #isolate params\n",
    "        comp_params = params[comp]\n",
    "        comp_se = se[comp]\n",
    "        comp_t = comp_params[:-1]/comp_se\n",
    "        comp_p = 1 - stats.t.cdf(np.abs(comp_t),df=(nobs-k)) + stats.t.cdf(-np.abs(comp_t),df=(nobs-k))\n",
    "        \n",
    "        #round everything\n",
    "        comp_params = np.round(comp_params,5)\n",
    "        comp_se = np.round(comp_se,5)\n",
    "        comp_t = np.round(comp_t,5)\n",
    "        comp_p = np.round(comp_p,5)\n",
    "        \n",
    "        lamb, lamb_se = comp_params[0], comp_se[0]\n",
    "        #lamb_t, lamb_p = comp_params[0],  comp_t[0], comp_p[0]\n",
    "        beta, beta_se, beta_t, beta_p = comp_params[1:-1], comp_se[1:], comp_t[1:], comp_p[1:]\n",
    "        sigma = comp_params[-1]\n",
    "        \n",
    "        if ncomp > 1:\n",
    "            f.write('\\\\textbf{Pr(phase %s)} & %s  & %s & & \\\\\\\\ \\\\\\\\ \\n'%(comp+1, lamb, lamb_se) )\n",
    "        \n",
    "        for i in range(k):\n",
    "            f.write('\\\\textbf{%s} & %s & (%s) & %s & %s \\\\\\\\ \\\\\\\\ \\n'%(xlabel[i],beta[i],beta_se[i],\n",
    "                                                                             beta_t[i],beta_p[i]) )\n",
    "        \n",
    "        #f.write('\\\\textbf{Variance} & %s &  & & \\\\\\\\ \\\\\\\\ \\n'%(sigma) )\n",
    "    f.write('\\\\hline \\\\\\\\ \\n')    \n",
    "    f.write('\\end{tabular} \\n')\n",
    "    f.close()\n",
    "    \n",
    "    #print output\n",
    "    f = open(fname, \"r\")\n",
    "    print(f.read())\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'YEAR', 'MONTH', 'DAY', 'SYSTEM', 'FMOZONE', 'VENDOR',\n",
      "       'COUNTY', 'LWW', 'LFMO', 'LGAS', 'LPOPUL', 'LQWW', 'COOLER', 'ESC', '3',\n",
      "       '6', '7', '9', 'INC', 'LWW_min1', 'LWW_min2', 'LWW_min3', 'LWW_min4',\n",
      "       'LWW_max1', 'LWW_max2', 'LWW_max3', 'LWW_max4'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "reg1 = pd.read_csv('data/clean_milk1.csv')\n",
    "print(reg1.columns)\n",
    "\n",
    "#variables names\n",
    "lmilk = ['LWW']\n",
    "auct_key = ['YEAR','MONTH','DAY','SYSTEM','FMOZONE']\n",
    "lcts = ['LFMO','LGAS','LPOPUL','LQWW']#,'LMEALS']\n",
    "dummies = ['COOLER','ESC']\n",
    "\n",
    "fekeys = list(reg1.columns[15:-9])\n",
    "\n",
    "\n",
    "lags = 4\n",
    "lagkeys = [l+str(i) for l in ['LWW_min','LWW_max'] for i in range(1,1+lags)]\n",
    "\n",
    "bid_key = auct_key + ['VENDOR'] + ['COUNTY']\n",
    "covariates = lcts + dummies + fekeys\n",
    "hist = ['INC'] + lagkeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "nice_ww = 'Bids (log-log)'\n",
    "nice_cov = ['(Intercept)', 'Raw milk', 'Gas',\n",
    "            'Population', 'Quantity', #'Meals',\n",
    "            'Cooler', 'Escalated', #+ fekeys\n",
    "            'Waco','St. Angelo', 'Austin', 'San Antonio']\n",
    "nice_lags = [l+str(i) for l in ['Min. lag \\#','Max. lag \\#'] for i in range(1,1+lags)]\n",
    "nice_lags = ['Incumbency'] + nice_lags\n",
    "\n",
    "print(len(nice_cov))\n",
    "print(len(covariates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\small \n",
      "\\begin{tabular}{lclc} \n",
      "\\hline \n",
      "\\textbf{Dep. Variable:} & Bids (log-log) & \\textbf{  R-squared: } &  0.157 \\\\ \n",
      "\\textbf{No. Observations:} & 3823 & \\textbf{ AIC:} & -8394.5 \\\\ \n",
      "\\end{tabular} \n",
      "\n",
      "\\begin{tabular}{lcccc} \n",
      "\\hline \n",
      "\\textbf{Phase 1} & \\textbf{Est.} & \\textbf{Std. Err.} &\\textbf{t} & \\textbf{P $>$ $|$ t $|$} \\\\ \n",
      "\\hline \\\\ \n",
      "\\textbf{(Intercept)} & -2.32719 & (0.07019) & -33.15553 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Raw milk} & 0.18609 & (0.02616) & 7.11463 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Gas} & 0.01513 & (0.00405) & 3.73775 & 0.00019 \\\\ \\\\ \n",
      "\\textbf{Population} & 0.00757 & (0.00183) & 4.1275 & 4e-05 \\\\ \\\\ \n",
      "\\textbf{Quantity} & -0.00353 & (0.002) & -1.76735 & 0.07725 \\\\ \\\\ \n",
      "\\textbf{Cooler} & 0.01853 & (0.00292) & 6.34468 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Escalated} & -0.02292 & (0.00276) & -8.31287 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Waco} & -0.06642 & (0.00411) & -16.15964 & 0.0 \\\\ \\\\ \n",
      "\\textbf{St. Angelo} & -0.04254 & (0.01185) & -3.59134 & 0.00033 \\\\ \\\\ \n",
      "\\textbf{Austin} & -0.08653 & (0.01378) & -6.27727 & 0.0 \\\\ \\\\ \n",
      "\\textbf{San Antonio} & -0.04479 & (0.00399) & -11.21354 & 0.0 \\\\ \\\\ \n",
      "\\hline \\\\ \n",
      "\\end{tabular} \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erichschulman/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:41: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "est0 = estimate(reg1['LWW'],sm.add_constant(reg1[covariates]),1)\n",
    "write_table('results/ols_results.tex', est0, labels=(nice_ww, nice_cov))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\small \n",
      "\\begin{tabular}{lclc} \n",
      "\\hline \n",
      "\\textbf{Dep. Variable:} & Bids (log-log) & \\textbf{  R-squared: } &  0.194 \\\\ \n",
      "\\textbf{No. Observations:} & 3823 & \\textbf{ AIC:} & -8547.5 \\\\ \n",
      "\\end{tabular} \n",
      "\n",
      "\\begin{tabular}{lcccc} \n",
      "\\hline \n",
      "\\textbf{Phase 1} & \\textbf{Est.} & \\textbf{Std. Err.} &\\textbf{t} & \\textbf{P $>$ $|$ t $|$} \\\\ \n",
      "\\hline \\\\ \n",
      "\\textbf{(Intercept)} & -1.53342 & (0.09904) & -15.48349 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Raw milk} & 0.12422 & (0.02617) & 4.74645 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Gas} & 0.01551 & (0.004) & 3.87531 & 0.00011 \\\\ \\\\ \n",
      "\\textbf{Population} & 0.00424 & (0.00184) & 2.30482 & 0.02123 \\\\ \\\\ \n",
      "\\textbf{Quantity} & -0.00135 & (0.00199) & -0.67607 & 0.49904 \\\\ \\\\ \n",
      "\\textbf{Cooler} & 0.01837 & (0.00287) & 6.39267 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Escalated} & -0.02192 & (0.0027) & -8.10935 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Waco} & -0.06851 & (0.00404) & -16.97702 & 0.0 \\\\ \\\\ \n",
      "\\textbf{St. Angelo} & -0.0469 & (0.01169) & -4.01353 & 6e-05 \\\\ \\\\ \n",
      "\\textbf{Austin} & -0.09748 & (0.01353) & -7.20557 & 0.0 \\\\ \\\\ \n",
      "\\textbf{San Antonio} & -0.04851 & (0.00396) & -12.24714 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Incumbency} & 0.02594 & (0.00557) & 4.66043 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Min. lag \\#1} & -0.00631 & (0.01895) & -0.3329 & 0.73923 \\\\ \\\\ \n",
      "\\textbf{Min. lag \\#2} & 0.05637 & (0.01886) & 2.98922 & 0.00281 \\\\ \\\\ \n",
      "\\textbf{Min. lag \\#3} & 0.0477 & (0.01903) & 2.50703 & 0.01222 \\\\ \\\\ \n",
      "\\textbf{Min. lag \\#4} & 0.02608 & (0.01886) & 1.38277 & 0.16682 \\\\ \\\\ \n",
      "\\textbf{Max. lag \\#1} & 0.12297 & (0.01866) & 6.59199 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Max. lag \\#2} & 0.02651 & (0.01847) & 1.43526 & 0.1513 \\\\ \\\\ \n",
      "\\textbf{Max. lag \\#3} & 0.04643 & (0.01845) & 2.51598 & 0.01191 \\\\ \\\\ \n",
      "\\textbf{Max. lag \\#4} & 0.03507 & (0.01792) & 1.95675 & 0.05045 \\\\ \\\\ \n",
      "\\hline \\\\ \n",
      "\\end{tabular} \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erichschulman/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:41: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "est1 = estimate(reg1['LWW'],sm.add_constant(reg1[covariates + hist]),1)\n",
    "write_table('results/hist_results.tex', est1, labels=(nice_ww, nice_cov + nice_lags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\small \n",
      "\\begin{tabular}{lclc} \n",
      "\\hline \n",
      "\\textbf{Dep. Variable:} & Bids (log-log) & \\textbf{  R-squared: } &  0.411 \\\\ \n",
      "\\textbf{No. Observations:} & 3823 & \\textbf{ AIC:} & -8992.4 \\\\ \n",
      "\\end{tabular} \n",
      "\n",
      "\\begin{tabular}{lcccc} \n",
      "\\hline \n",
      "\\textbf{Phase 1} & \\textbf{Est.} & \\textbf{Std. Err.} &\\textbf{t} & \\textbf{P $>$ $|$ t $|$} \\\\ \n",
      "\\hline \\\\ \n",
      "\\textbf{Pr(phase 1)} & 0.32055  & 0.25601 & & \\\\ \\\\ \n",
      "\\textbf{(Intercept)} & -2.7301 & (0.05957) & -45.82928 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Raw milk} & 0.35829 & (0.02213) & 16.19316 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Gas} & 0.00427 & (0.00357) & 1.19809 & 0.23096 \\\\ \\\\ \n",
      "\\textbf{Population} & -0.00257 & (0.0017) & -1.5115 & 0.13074 \\\\ \\\\ \n",
      "\\textbf{Quantity} & 0.00172 & (0.00185) & 0.92942 & 0.35273 \\\\ \\\\ \n",
      "\\textbf{Cooler} & 0.00677 & (0.00249) & 2.71818 & 0.00659 \\\\ \\\\ \n",
      "\\textbf{Escalated} & -0.00587 & (0.00227) & -2.58136 & 0.00988 \\\\ \\\\ \n",
      "\\textbf{Waco} & -0.17445 & (0.00366) & -47.71652 & 0.0 \\\\ \\\\ \n",
      "\\textbf{St. Angelo} & -0.07934 & (0.01022) & -7.76645 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Austin} & -0.221 & (0.01114) & -19.83021 & 0.0 \\\\ \\\\ \n",
      "\\textbf{San Antonio} & -0.18915 & (0.00362) & -52.22881 & 0.0 \\\\ \\\\ \n",
      "\\hline \n",
      "\\textbf{Phase 2} & \\textbf{Est.} & \\textbf{Std. Err.} &\\textbf{t} & \\textbf{P $>$ $|$ t $|$} \\\\ \n",
      "\\hline \\\\ \n",
      "\\textbf{Pr(phase 2)} & 0.67945  & 0.25601 & & \\\\ \\\\ \n",
      "\\textbf{(Intercept)} & -2.24976 & (0.08144) & -27.62469 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Raw milk} & 0.16265 & (0.03041) & 5.34803 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Gas} & -0.00182 & (0.00465) & -0.3914 & 0.69552 \\\\ \\\\ \n",
      "\\textbf{Population} & 0.0097 & (0.00205) & 4.72358 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Quantity} & -0.00222 & (0.00224) & -0.98913 & 0.32266 \\\\ \\\\ \n",
      "\\textbf{Cooler} & 0.01851 & (0.00338) & 5.48464 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Escalated} & -0.02307 & (0.00325) & -7.09146 & 0.0 \\\\ \\\\ \n",
      "\\textbf{Waco} & -0.02475 & (0.00468) & -5.29076 & 0.0 \\\\ \\\\ \n",
      "\\textbf{St. Angelo} & -0.03042 & (0.01362) & -2.23387 & 0.02555 \\\\ \\\\ \n",
      "\\textbf{Austin} & -0.01724 & (0.01634) & -1.05536 & 0.29133 \\\\ \\\\ \n",
      "\\textbf{San Antonio} & 0.00369 & (0.00456) & 0.80937 & 0.41835 \\\\ \\\\ \n",
      "\\hline \\\\ \n",
      "\\end{tabular} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "est2 = estimate(reg1['LWW'],sm.add_constant(reg1[covariates]),2)\n",
    "write_table('results/prelim_results.tex', est2, labels=(nice_ww, nice_cov))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7.6243720582619074, 7.56500250531668, 3.084839564039558e-14, 4.841818799677707e-14)\n"
     ]
    }
   ],
   "source": [
    "test1 = estimate(Y, sm.add_constant(X), 2)\n",
    "test2 = estimate(Y, sm.add_constant(X), 1)\n",
    "\n",
    "def nonnested_test(model1,model2):\n",
    "    \"\"\"test for non nested models quang vuong\"\"\"\n",
    "    \n",
    "    params1, se1, r21, y1, x1, ncomp1, ll1 = model1\n",
    "    params2, se2, r22, y2, x2, ncomp2, ll2 = model2\n",
    "    nobs, k = x1.shape\n",
    "    \n",
    "    k1 = params1.shape[1]*ncomp1 - 1 \n",
    "    k2 = params2.shape[1]*ncomp2 - 1\n",
    "    \n",
    "    var1 = (ll1 -ll2).std()\n",
    "    test1 = (ll1.sum() - ll2.sum() - k1 + k2)*nobs**(-.5)\n",
    "    test1 = test1/var1\n",
    "    p1 = 1 - stats.t.cdf(np.abs(test1),df=(nobs-k1-k2)) + stats.t.cdf(-np.abs(test1),df=(nobs-k1-k2))\n",
    "    \n",
    "    var2 =  ((ll1 - ll2)**2).mean()**.5\n",
    "    test2 = (ll1.sum() - ll2.sum() - k1 + k2 )*nobs**(-.5)\n",
    "    test2 = test2/var2\n",
    "    p2 = 1 - stats.t.cdf(np.abs(test2),df=(nobs-k1-k2)) + stats.t.cdf(-np.abs(test2),df=(nobs-k1-k2))\n",
    "    \n",
    "    return test1, test2, p1, p2\n",
    "\n",
    "print(nonnested_test(est2,est1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_nonnested(model1,model2,fname):\n",
    "    test1, test2, p1, p2 = nonnested_test(model1,model2)\n",
    "    test1, test2, p1, p2 = np.round(test1,5), np.round(test2,5), np.round(p1,5), np.round(p2,5) \n",
    "    f = open(fname, \"w+\")\n",
    "    f.write('\\\\begin{tabular}{lcc}')\n",
    "    f.write('\\n\\\\hline \\n & \\\\textbf{t} & \\\\textbf{P $>$ $|$ t $|$} \\\\\\\\')\n",
    "    f.write('\\n\\\\hline')\n",
    "    f.write('\\n\\\\textbf{Test 1} & %s & %s \\\\\\\\'%(test1,p1))\n",
    "    f.write('\\n\\\\textbf{Test 2} & %s & %s \\\\\\\\'%(test2,p2))\n",
    "    f.write('\\\\hline \\\\\\\\ \\n')   \n",
    "    f.write('\\n\\\\end{tabular}\\n')\n",
    "    f.close()\n",
    "\n",
    "write_nonnested(est2,est1,'results/test_stat.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
