{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.base.model import GenericLikelihoodModel\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import warnings\n",
    "\n",
    "from statsmodels.tsa.regime_switching.markov_autoregression import MarkovAutoregression\n",
    "from statsmodels.tsa.regime_switching.markov_regression import MarkovRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate some fake data\n",
    "\n",
    "n = 1000\n",
    "beta01, beta11 = 5,-3\n",
    "beta02, beta12 = 2, 4\n",
    "\n",
    "#set up regression mixture\n",
    "x1 = np.random.uniform(0, 10, size=400)\n",
    "x2 = np.random.uniform(0, 10, size=600)\n",
    "\n",
    "y1 = beta01 + beta11*x1 + np.random.normal(scale=4.0, size=400)\n",
    "y2 = beta02 + beta12*x2 + np.random.normal(scale=1.0,size=600)\n",
    "\n",
    "x = np.concatenate([x1, x2])\n",
    "y = np.concatenate([y1, y2])\n",
    "\n",
    "\n",
    "#set up 2 component mixture\n",
    "a1 = np.random.normal(0, 1, size=600)\n",
    "a2 = np.random.normal(5, 3, size=400)\n",
    "a = np.concatenate([a1,a2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          SwitchingRegression Results                          \n",
      "===============================================================================\n",
      "Dep. Variable:                       y   Log-Likelihood:                -1374.2\n",
      "Model:             SwitchingRegression   AIC:                             2752.\n",
      "Method:             Maximum Likelihood   BIC:                             2762.\n",
      "Date:                 Sat, 27 Apr 2019                                         \n",
      "Time:                         11:37:08                                         \n",
      "No. Observations:                 1000                                         \n",
      "Df Residuals:                      998                                         \n",
      "Df Model:                            1                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const0         0.7984      0.459      1.739      0.082      -0.101       1.698\n",
      "x10           -2.3848      0.077    -31.098      0.000      -2.535      -2.234\n",
      "sigma0         3.5233      0.117     30.208      0.000       3.295       3.752\n",
      "const1         1.3098      0.092     14.199      0.000       1.129       1.491\n",
      "x11            4.0556      0.015    270.510      0.000       4.026       4.085\n",
      "sigma1         1.0252      0.028     36.625      0.000       0.970       1.080\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "class SwitchingRegression(GenericLikelihoodModel):\n",
    "    \n",
    "    def __init__(self, endog, exog, ncomp=2, switch_var=True):\n",
    "        super(SwitchingRegression, self).__init__(endog, exog)\n",
    "        \n",
    "        nobs, k = self.exog.shape\n",
    "        self.ncomp = ncomp\n",
    "        self.nparams = (k+1)*ncomp\n",
    "        \n",
    "        #random start\n",
    "        np.random.seed(0)\n",
    "        weights = np.random.uniform(size=(nobs,ncomp))\n",
    "        denom = np.repeat(weights.sum(axis= 1),self.ncomp).reshape(nobs,ncomp)\n",
    "        self.weights = (weights/denom)\n",
    "        \n",
    "        #adjust param names\n",
    "        param_names = []\n",
    "        for comp in range(ncomp):\n",
    "            for name in self.data.xnames:\n",
    "                param_names.append(name+str(comp))\n",
    "            param_names.append('sigma'+str(comp))\n",
    "        \n",
    "        self.data.xnames = param_names\n",
    "        \n",
    "        \n",
    "    \n",
    "    def nloglikeobs(self, params):\n",
    "        \"\"\"do maximum likelihood estimation\"\"\"\n",
    "\n",
    "        nobs, k = self.exog.shape\n",
    "        likelihood = []\n",
    "        for comp in range(self.ncomp):\n",
    "            \n",
    "            #get params\n",
    "            comp_params = params[comp*(k+1): (comp+1)*(k + 1)]\n",
    "            beta = comp_params[:-1]\n",
    "            sigma = comp_params[-1]\n",
    "            weights = self.weights[:,comp]\n",
    "            \n",
    "            #calculate likelihood from formula\n",
    "            beta = np.tile(beta,nobs).reshape(nobs,k)\n",
    "            means = (beta*self.exog).sum(axis=1)\n",
    "            comp_like = -np.log(sigma)-.5*((self.endog-means)/sigma)**2 \n",
    "            comp_like = weights*comp_like\n",
    "            likelihood.append(comp_like)\n",
    "\n",
    "        return -np.array(likelihood).sum().sum()\n",
    "    \n",
    "    \n",
    "    def e_step(self, params):\n",
    "        #recompute weights\n",
    "        nobs, k = self.exog.shape\n",
    "        weights =[]\n",
    "        for comp in range(self.ncomp):\n",
    "            comp_params = params[comp*(k+1): (comp+1)*(k + 1)]\n",
    "            beta = comp_params[:-1]\n",
    "            sigma = comp_params[-1]\n",
    "              \n",
    "            beta = np.tile(beta,nobs).reshape(nobs, k)\n",
    "            mean = (beta*self.exog).sum(axis=1)\n",
    "            wi = np.exp(-.5*((self.endog - mean)/sigma)**2)/(sigma*(2*math.pi)**.5)\n",
    "            weights.append(np.maximum(wi,1e-5))\n",
    "            \n",
    "        #update loop variables\n",
    "        weights = np.array(weights).transpose()\n",
    "        denom = np.repeat(weights.sum(axis= 1),self.ncomp).reshape(nobs,self.ncomp)\n",
    "        return (weights/denom)\n",
    "    \n",
    "    \n",
    "    def fit(self, **kwds):\n",
    "        \"\"\"print that we did it\"\"\"\n",
    "        nobs, k = self.exog.shape\n",
    "        model = None\n",
    "        \n",
    "        for i in range(10):\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.filterwarnings(\"ignore\")\n",
    "                start = np.ones(len(self.data.xnames))\n",
    "                model = super(SwitchingRegression, self).fit(disp=False, start_params=start, method='nm')\n",
    "                weights = self.e_step(model.params)\n",
    "                self.weights = weights\n",
    "        \n",
    "        return model\n",
    "\n",
    "\n",
    "model = SwitchingRegression(y, sm.add_constant(x))\n",
    "result = model.fit()\n",
    "print result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
