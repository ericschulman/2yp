{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.base.model import GenericLikelihoodModel\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "from statsmodels.tsa.regime_switching.markov_autoregression import MarkovAutoregression\n",
    "from statsmodels.tsa.regime_switching.markov_regression import MarkovRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate some fake data\n",
    "\n",
    "n = 1000\n",
    "beta01, beta11 = 5,-3\n",
    "beta02, beta12 = 2, 4\n",
    "\n",
    "#set up regression mixture\n",
    "x1 = np.random.uniform(0, 10, size=400)\n",
    "x2 = np.random.uniform(0, 10, size=600)\n",
    "\n",
    "y1 = beta01 + beta11*x1 + np.random.normal(scale=2.0, size=400)\n",
    "y2 = beta02 + beta12*x2 + np.random.normal(scale=4.0,size=600)\n",
    "\n",
    "x = np.concatenate([x1, x2])\n",
    "y = np.concatenate([y1, y2])\n",
    "\n",
    "\n",
    "#set up 2 component mixture\n",
    "a1 = np.random.normal(0, 1, size=600)\n",
    "a2 = np.random.normal(5, 3, size=400)\n",
    "a = np.concatenate([a1,a2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EM convergence achieved] \n",
      "\n",
      "========================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erichschulman/anaconda2/lib/python2.7/site-packages/statsmodels/base/model.py:488: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n",
      "/home/erichschulman/anaconda2/lib/python2.7/site-packages/statsmodels/base/model.py:508: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/home/erichschulman/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:78: RuntimeWarning: invalid value encountered in divide\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'dropna'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-a40d454a09ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClusters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_constant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmle_retvals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-a40d454a09ca>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, start_params, maxiter, maxfun, **kwds)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0;34m'[EM convergence achieved] \\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mprint\u001b[0m\u001b[0;34m'========================================================'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0;32mprint\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m'weights: %s'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m'========================================================\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'dropna'"
     ]
    }
   ],
   "source": [
    "class Clusters(GenericLikelihoodModel):\n",
    "    \n",
    "    def __init__(self, endog, exog, ncomp=2, switch_var=True):\n",
    "        super(Clusters, self).__init__(endog, exog)\n",
    "        \n",
    "        nobs, k = self.exog.shape\n",
    "        self.ncomp = ncomp\n",
    "        self.nparams = k*ncomp + 2\n",
    "        #self.weights = np.tile(np.ones(ncomp)/(1.*ncomp),(nobs,1))\n",
    "        \n",
    "        #random start\n",
    "        np.random.seed(0)\n",
    "        weights = np.random.uniform(size=(nobs,ncomp))\n",
    "        denom = np.repeat(weights.sum(axis= 1),self.ncomp).reshape(nobs,ncomp)\n",
    "        self.weights = (weights/denom)\n",
    "        \n",
    "        #adjust param names\n",
    "        param_names = []\n",
    "        for comp in range(ncomp):\n",
    "            for name in self.data.xnames:\n",
    "                param_names.append(name+str(comp))\n",
    "            param_names.append('sigma'+str(comp))\n",
    "        self.data.xnames = param_names\n",
    "     \n",
    "    \n",
    "    def nloglikeobs(self, params, v=False):\n",
    "        \"\"\"do maximum likelihood estimation\"\"\"\n",
    "        nobs, k = self.exog.shape\n",
    "        comp_likes = []\n",
    "        for comp in range(self.ncomp):\n",
    "            comp_params = params[comp*(k+1): (comp+1)*(k + 1)]\n",
    "            beta = comp_params[:-1]\n",
    "            sigma = comp_params[-1]\n",
    "            \n",
    "            beta = np.tile(beta,nobs).reshape(nobs,k)\n",
    "            means = (beta*self.exog).sum(axis=1) \n",
    "            like = stats.norm.logpdf(self.endog- means, loc=0, scale=1)\n",
    "            comp_likes.append(like)\n",
    "\n",
    "        comp_likes = np.array(comp_likes).transpose()\n",
    "        comp_likes = self.weights*comp_likes\n",
    "        \n",
    "        return -comp_likes.sum().sum()\n",
    "    \n",
    "    \n",
    "    \n",
    "    def fit(self, start_params=None, maxiter=1000, maxfun=5000, **kwds):\n",
    "        \"\"\"print that we did it\"\"\"\n",
    "        tol = 1e-8\n",
    "        nobs, k = self.exog.shape\n",
    "        \n",
    "        #loop variables\n",
    "        maxiter = 5\n",
    "        diff = 1\n",
    "        model = None\n",
    "        \n",
    "        while diff > tol and maxiter >=0 :\n",
    "\n",
    "            start = np.linspace(1.,5., len(self.data.xnames))\n",
    "            model = super(Clusters, self).fit(disp=False, start_params=start,\n",
    "                                             method='nm', maxiter=200, full_output=True,  retall=True)\n",
    "            weights = []\n",
    "            \n",
    "            #recompute weights\n",
    "            for comp in range(self.ncomp):\n",
    "                comp_params = model.params[comp*(k+1): (comp+1)*(k + 1)]\n",
    "                beta = comp_params[:-1]\n",
    "                sigma = comp_params[-1]\n",
    "                \n",
    "                beta = np.tile(beta,nobs).reshape(nobs, k)\n",
    "                mean = (beta*self.exog).sum(axis=1)\n",
    "                weights.append( stats.norm.pdf(self.endog - mean, loc=0, scale=1) )\n",
    "\n",
    "            \n",
    "            #update loop variables\n",
    "            weights = np.array(weights).transpose()\n",
    "            denom = np.repeat(weights.sum(axis= 1),self.ncomp).reshape(nobs,self.ncomp)\n",
    "            weights = (weights/denom)\n",
    "            \n",
    "            \n",
    "            #this is hacky\n",
    "            diff = np.sort(weights, axis=1)- np.sort(self.weights, axis=1)\n",
    "            diff = np.abs(diff).mean()\n",
    "            \n",
    "            maxiter = maxiter-1\n",
    "            self.weights = weights\n",
    "        \n",
    "        if maxiter > 0:\n",
    "            print '[EM convergence achieved] \\n'\n",
    "            print'========================================================'\n",
    "        print 'weights: %s'%self.weights.mean(axis=0)\n",
    "        print'========================================================\\n'\n",
    "        \n",
    "        return model\n",
    " \n",
    "        \n",
    "#test case #1 - easy 2 component mixture\n",
    "model = Clusters(y, sm.add_constant(x))\n",
    "                               \n",
    "result = model.fit()\n",
    "print result.summary()\n",
    "print result.mle_retvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
